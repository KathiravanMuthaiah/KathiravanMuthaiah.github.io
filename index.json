[{"categories":["WebDevelopment","PersonalProjects"],"content":"Step-by-step guide to building a personal website using Hugo and LoveIt theme, deployed on GitHub Pages with a custom subdomain.","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"Building a personal website can be simple, elegant, and completely under your control with Hugo v0.143.1 and the LoveIt v0.3.0 theme. In this post, I share my step-by-step journey of creating my website, including installation, configuration, GitHub Pages deployment, and a custom subdomain setup. Discover how the Hugo + LoveIt combo enables a fast, SEO-friendly static site for personal branding. ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:0:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"1Ô∏è‚É£ Choosing Hugo and LoveIt When planning my personal website, I had three key requirements: Markdown-first workflow ‚Üí Easy content creation Lightweight static hosting ‚Üí Ideal for GitHub Pages deployment Modern, clean design ‚Üí Focus on readability and mobile responsiveness After evaluating several Hugo themes, I selected: Hugo Extended Binary ‚Üí Fast, portable, no complex dependencies LoveIt theme ‚Üí Responsive, SEO-friendly, and perfect for blogs \u0026 portfolios ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:1:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"2Ô∏è‚É£ Local Setup Setting up Hugo locally is the first step to building your site. Here‚Äôs how I prepared my environment on Linux 64-bit: Install Hugo Extended # Create tools folder mkdir -p /opt/software/hugo cd /opt/software/hugo # Download Hugo Extended binary wget https://github.com/gohugoio/hugo/releases/download/v0.143.1/hugo_extended_0.143.1_Linux-64bit.tar.gz # Extract and clean tar -xvzf hugo_extended_0.143.1_Linux-64bit.tar.gz rm hugo_extended_0.143.1_Linux-64bit.tar.gz # Verify installation ./hugo version Expected output: hugo v0.143.1-extended+linux/amd64 BuildDate=xxxx (Optional) Add Hugo to your PATH echo 'export PATH=/opt/software/hugo:$PATH' \u003e\u003e ~/.coderc source ~/.coderc Once Hugo is installed, create a new site and set up the LoveIt theme: Initialize project hugo new site OwnWebsite cd OwnWebsite git init Add LoveIt theme as submodule and ensure exact version is taken git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt git add .gitmodules themes/LoveIt cd ./themes/LoveIt git fetch --all --tags git checkout v0.3.0 git pull .gitignore Setup for Submodule Edit# Ignore all other themes except LoveIt submodule themes/*/ !themes/LoveIt/ Configure hugo.toml baseURL = \"https://.github.io/\" title = \"My Personal Website\" theme = [\"LoveIt\"] ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:2:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"3Ô∏è‚É£ Creating Your First Post \u0026 Handling Images Hugo page bundles make it easy to keep Markdown and images together. Here‚Äôs how I created my first blog post with a sample image: To create the first post: hugo new posts/first-post/index.md Add images inside the post folder: content/posts/first-post/ index.md SampleImage.jpg Reference images in Markdown: ![Legend Walks](SampleImage.jpg) Example front matter for a blog post --- title: \"My First Blog Post\" subtitle: \"Learning Hugo + LoveIt\" date: 2025-07-31T10:00:00+02:00 draft: false tags: [\"hugo\", \"loveit\", \"learning\"] categories: [\"blog\"] author: \"Your Name\" summary: \"This is my first post on my personal site using Hugo LoveIt theme. Exploring markdown, code blocks, images, and shortcodes.\" --- Welcome to my **first blog post** with the [LoveIt](https://hugoloveit.com) theme! ## üìå Key Highlights 1. Markdown is **clean and fast** 2. LoveIt theme provides: - TOC support - Code highlighting - Image lightbox 3. Deployment via **GitHub Pages** is simple --- ![Legend Walks](SampleImage.jpg) ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:3:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"4Ô∏è‚É£ Deploying to GitHub Pages Once your site is ready, deploy it to GitHub Pages for free hosting: Created public Pages repo: \u003cusername\u003e.github.io Add public/ folder as submodule (gh-pages branch): git submodule add -b gh-pages git@github.com:/.github.io.git public Build \u0026 deploy your site hugo --minify cd public git add . git commit -m \"Deploy site\" git push origin gh-pages Enable GitHub Pages ‚Üí In gh-pages branch Go to Repo Settings ‚Üí Pages Select branch ‚Üí ‚úÖ Live! ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:4:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"5Ô∏è‚É£ Adding a Custom Subdomain To make your site accessible via a personal subdomain like ownwebsite.example.com instead of \u003cusername\u003e.github.io: Add a CNAME Record in DNS Host: ownwebsite Type: CNAME Points to: \u003cusername\u003e.github.io Verify DNS propagation dig ownwebsite.example.com Enable HTTPS on GitHub Pages Go to Repo ‚Üí Settings ‚Üí Pages Check ‚ÄúEnforce HTTPS‚Äù Within 30 minutes, the custom domain with HTTPS was active. ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:5:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["WebDevelopment","PersonalProjects"],"content":"6Ô∏è‚É£ Key Lessons Learned Here are the top takeaways from building my site with Hugo \u0026 LoveIt: Use Hugo Extended Binary ‚Üí Cleaner setup, supports SCSS \u0026 modern themes without system pollution. Manage public/ and themes/ as Git submodules ‚Üí Keeps deployment and theme updates under version control. Organize posts as page bundles ‚Üí Store Markdown and images together to avoid 404 errors. Verify theme \u0026 Hugo version compatibility ‚Üí Prevents build errors and broken layouts. Happy Learning ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT ","date":"2025-07-31","objectID":"/posts/how-i-built-my-personal-website/:6:0","tags":["Hugo","LoveIt","GitHub Pages","Static Site","Personal Website"],"title":"How I Built My Personal Website with Hugo \u0026 LoveIt","uri":"/posts/how-i-built-my-personal-website/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"Part 2 of the Docker Infrastructure Series focuses on building a reusable Kafka + Zookeeper module with custom Dockerfiles, debugging tools, Prometheus JMX metrics, topic initialization, and disciplined infra engineering.","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"üöÄ Building Infrastructure with Docker ‚Äî Part 2 ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:0:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"Kafka + Zookeeper with Dedicated Dockerfiles, Better Debugging, and Real Observability In Part 1, we created a reusable PostgreSQL module with a disciplined scaffold: pinned versions, Makefile lifecycle, health checks, and local bind-mount volumes. In this part, we focus on Kafka + Zookeeper ‚Äî but not as a bare-minimum broker. We‚Äôll run Kafka as an independent, reusable module, enriched with: Extra debugging tools inside the container Prometheus-friendly JMX metrics Scripted topic initialization for realistic usage The same canonical project structure and Makefile contract This module is designed to be dropped into any project as a ready-to-use event backbone. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:1:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"üéØ Objectives for the Kafka Module From the requirements, the Kafka setup must satisfy: kafkaRequirements Area Requirement Deployment Local via Docker Compose Modularity Kafka lives in its own subfolder, sharing a Docker bridge network Persistence Message logs in ./docker-volume/kafka/ Observability JMX exporter enabled, Prometheus-ready metrics exposed Debuggability Container image enriched with basic debugging tools Security Prepared for future mTLS / JWT / hardened configs (not forced yet) We keep Kafka fully independent as a module, but it‚Äôs ready to plug into other infra (Prometheus, Grafana, Debezium, etc.) later. üì¶ High-Level Architecture Your reference file defines the new compose layout (Kafka + Zookeeper built from Dockerfiles). This architecture now looks like: Zookeeper starts first ‚Üí Kafka waits for readiness ‚Üí Kafka registers properly with Zookeeper ‚Üí JMX metrics become available ‚Üí Topics can be initialized. This sequence ensures deterministic startup. üß± Folder Structure (Canonical, Clean, Uniform) modules/kafka/ infra/ docker-compose.yml Dockerfile.kafka Dockerfile.zookeeper docker-volume/ kafka/ zookeeper/ init/ init-topics.sh jmx-exporter/ kafka-2_0_0.yml scripts/ test_health.sh .env.example Makefile Jenkinsfile docs/ README.md requirements.md design-intent.md diagrams/ This matches the structure defined in Part-0 and Part-1 ‚Äî every module in this series follows this consistent pattern so that once you learn one, you master them all. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:2:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"üß± Components in This Module From the requirement spec: kafkaRequirements Service Source Role Kafka Broker Bitnami Custom image kafka (Dockerfile) Core message broker + debug tooling Zookeeper Bitnami Custom image Zookeeper (Dockerfile) Coordination and metadata JMX Exporter Conf jmx-exporter/kafka-2_0_0.yml Exposes Kafka metrics to Prometheus Key points: Kafka runs from a custom Dockerfile that includes additional debug tools. Debug tools are installed via requirements_debug.sh at image build time, providing utilities like curl, net-tools, ping, lsof, procps, htop, etc., for live troubleshooting inside the container. requirements_debug JMX metrics are enabled and configured using kafka-2_0_0.yml, so Prometheus can scrape Kafka with minimal additional setup. kafkaRequirements ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:3:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"üõ† Debug-Enriched Kafka Image The Kafka broker image is built from a dedicated Dockerfile (in this module), which uses requirements_debug.sh to install a curated set of CLI tools: requirements_debug curl net-tools (e.g., netstat) iputils-ping dnsutils iproute2 lsof procps (ps, top) less, vim, nano htop This means when something goes wrong, you don‚Äôt have to rebuild images just to run basic diagnostics; you can: Inspect network connectivity directly from inside the broker container. Test DNS resolution and connectivity to other services. Inspect open ports and processes. For infra education and local troubleshooting, this is a big win. üõ† Kafka as a Custom Image (Dockerfile.kafka) Our Kafka Dockerfile now: Installs Kafka from the official Apache distribution Installs debugging utilities using requirements_debug.sh Enables JMX exporter for Prometheus Uses .env to configure listener host, ports, and broker ID Uses docker-volume/kafka/ for logs and persistent storage ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:4:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"Why a custom Dockerfile? Because real clusters aren‚Äôt built from ‚Äútutorial images.‚Äù We need: Predictability Debuggability Observability Reusability across projects This aligns exactly with enterprise design constraints. FROM bitnamilegacy/kafka:3.4 # Copy the JMX config directory COPY jmx-exporter/ /jmx_exporter/ # Copy Kafka topic initialization scripts #COPY init/ /opt/kafka-init/ # Ensure permissions are correct USER root # debugging steps start --- COPY requirements_debug.sh . # Conditionally install debug tools RUN if [ -f requirements_debug.sh ]; then \\ echo \"[INFO] Found requirements_debug.sh. Executing...\"; \\ chmod +x requirements_debug.sh \u0026\u0026 ./requirements_debug.sh; \\ else \\ echo \"[INFO] No debug script found. Skipping...\"; \\ fi # debugging steps end --- #RUN chmod +x /opt/kafka-init/init-topics.sh RUN chown -R 1001:1001 /jmx_exporter RUN chown -R 1001:1001 /bitnami/kafka #RUN chown -R 1001:1001 /opt/kafka-init USER 1001 ü¶ç Zookeeper as a Custom Image (Dockerfile.zookeeper) We no longer rely on Bitnami or Confluent base images. Our Zookeeper Dockerfile: Installs Zookeeper natively Includes the same debugging tools strategy Exposes metrics-friendly configuration Uses docker-volume/zookeeper/ for its data Keeps everything deterministic and version-pinned This also unlocks the option to add: Zookeeper JMX metrics ACLs Multi-node quorum setups in future parts if needed. FROM bitnamilegacy/zookeeper:3.8 # Ensure permissions are correct USER root # debugging steps start --- COPY requirements_debug.sh . # Conditionally install debug tools RUN if [ -f requirements_debug.sh ]; then \\ echo \"[INFO] Found requirements_debug.sh. Executing...\"; \\ chmod +x requirements_debug.sh \u0026\u0026 ./requirements_debug.sh; \\ else \\ echo \"[INFO] No debug script found. Skipping...\"; \\ fi # debugging steps end --- RUN chown -R 1001:1001 /bitnami/zookeeper USER 1001 üì¶ docker-compose.yml (using the Dockerfiles) Your reference file defines the new compose layout (Kafka + Zookeeper built from Dockerfiles). services: zookeeper-bank: build: context: . dockerfile: Dockerfile.zookeeper image: zookeeper-bank container_name: zookeeper-bank # restart: unless-stopped # user: \"1001:1001\" ports: - \"${ZOOKEEPER_CLIENT_PORT}:2181\" env_file: - .env environment: - ALLOW_ANONYMOUS_LOGIN=yes volumes: - ./docker-volume/zookeeper/data:/bitnami/zookeeper extra_hosts: - \"host.docker.internal:172.17.0.1\" healthcheck: test: [\"CMD-SHELL\", \"exit 0\"] interval: 10s timeout: 5s retries: 5 start_period: 20s networks: - bankingnet kafka-bank: build: context: . dockerfile: Dockerfile.kafka image: kafka-bank container_name: kafka-bank # restart: unless-stopped # user: \"1001:1001\" depends_on: - zookeeper-bank ports: - \"${KAFKA_LISTENER_PORT}:${KAFKA_LISTENER_PORT}\" - 9094:9094 - \"${KAFKA_JMX_PORT}:${KAFKA_JMX_PORT}\" # for JMX_exporter env_file: - .env environment: - KAFKA_BROKER_ID=1 - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper-bank:2181 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,EXTERNAL://0.0.0.0:9094 - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka-bank:9092,EXTERNAL://localhost:9094 - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false - ALLOW_PLAINTEXT_LISTENER=yes - KAFKA_JMX_PORT=${KAFKA_JMX_PORT} - KAFKA_OPTS=-javaagent:/jmx_exporter/jmx_prometheus_javaagent-0.18.0.jar=${KAFKA_JMX_PORT}:/jmx_exporter/kafka-2_0_0.yml volumes: - ./docker-volume/kafka/data:/bitnami/kafka extra_hosts: - \"host.docker.internal:172.17.0.1\" healthcheck: test: [\"CMD-SHELL\", \"exit 0\"] interval: 10s timeout: 5s retries: 5 start_period: 30s networks: - bankingnet networks: bankingnet: external: true üì° JMX Exporter for Kafka Metrics Kafka exposes JMX ‚Äújmx_prometheus_javaagent-0.18.0.jar‚Äù on a configured port (e.g., 9404). We mount: jmx-exporter/kafka-2_0_0.yml lowercaseOutputName: true lowercaseOutputLabelNames: true rules: - pattern: \"kafka.server","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:4:1","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"üß™ Topic Initialization Script (Realistic Test Topics) Instead of manually creating topics on the CLI each time, the module ships with init/init-topics.sh, which: Lists existing topics, and Creates a set of predefined topics with realistic names and partition counts: init-topics topics=( \"transaction_events:3\" \"account_changes:2\" \"audit_logs:1\" \"document_uploaded:1\" \"metrics.service_health:1\" \"metrics.db_health:1\" \"metrics.kafka_health:1\" ) For each \u003cname\u003e:\u003cpartitions\u003e pair, it runs: docker run --rm -it --network \"${NETWORK}\" -e KAFKA_JMX_OPTS=\"\" bitnami/kafka:3.4 \\ kafka-topics.sh --create --if-not-exists \\ --bootstrap-server \"$BOOTSTRAP_SERVER\" \\ --replication-factor 1 \\ --partitions \"$partitions\" \\ --topic \"$name\" using: BOOTSTRAP_SERVER=\"kafka-broker:9092\" NETWORK=\"bankingnet\" init-topics This approach has key advantages: Topic initialization is idempotent (--if-not-exists). No need to exec into the broker; everything is driven via ephemeral kafka CLI containers on the same Docker network. The topics match a realistic banking/microplatform use case: transactions, account changes, audit, and metrics streams. You can run the script any time you reset Kafka. ü©∫ Smoke Testing (Health + Topic Listing) The module uses an improved test_health.sh which validates: Zookeeper health Kafka health Kafka CLI connectivity Topic listing or existence checks This is the same pattern used in Part-1 for PostgreSQL, but extended for Kafka‚Äôs more complex lifecycle. üîß Makefile Lifecycle ( Pattern as Part-1) # Kafka module Makefile # ---- Config ---- ENV_FILE ?= .env COMPOSE_FILE ?= infra/docker-compose.kafka.yml PROJECT_NAME ?= kafka-module DC := docker compose --env-file $(ENV_FILE) -f $(COMPOSE_FILE) -p $(PROJECT_NAME) # ---- Phony Targets ---- .PHONY: help init build up down restart logs ps test clean topics-init topics-list help: @echo \"Kafka module targets:\" @echo \" init - prepare env file, folders, and pull/build images\" @echo \" build - build Kafka and Zookeeper images\" @echo \" up - start Kafka + Zookeeper in background\" @echo \" down - stop containers\" @echo \" restart - restart stack\" @echo \" logs - follow logs for all services\" @echo \" ps - show container status\" @echo \" test - run health + smoke checks\" @echo \" topics-init - create standard test topics (init-topics.sh)\" @echo \" topics-list - list topics using kafka-topics.sh\" @echo \" clean - stop stack and delete data volumes (with confirmation)\" init: @if [ ! -f \"$(ENV_FILE)\" ]; then \\ if [ -f \".env.example\" ]; then \\ echo \"Creating $(ENV_FILE) from .env.example\"; \\ cp .env.example $(ENV_FILE); \\ else \\ echo \"ERROR: .env.example not found. Create it first.\"; \\ exit 1; \\ fi \\ else \\ echo \"$(ENV_FILE) already exists, not overwriting.\"; \\ fi @mkdir -p docker-volume/kafka docker-volume/zookeeper @echo \"Pulling / building images (if required)...\" @$(DC) pull || true @$(DC) build --pull build: @$(DC) build --pull up: @$(DC) up -d down: @$(DC) down restart: down up logs: @$(DC) logs -f ps: @$(DC) ps test: @./scripts/test_health.sh $(ENV_FILE) topics-init: @./init/init-topics.sh topics-list: @if [ ! -f \"$(ENV_FILE)\" ]; then \\ echo \"Env file $(ENV_FILE) not found. Run 'make init' first.\"; \\ exit 1; \\ fi; \\ . \"$(ENV_FILE)\"; \\ KAFKA_CONTAINER_NAME=\"$${KAFKA_CONTAINER_NAME:-kafka-broker}\"; \\ KAFKA_LISTENER_PORT=\"$${KAFKA_LISTENER_PORT:-9092}\"; \\ echo \"Listing topics via $$KAFKA_CONTAINER_NAME on port $$KAFKA_LISTENER_PORT\"; \\ docker exec -it \"$$KAFKA_CONTAINER_NAME\" \\ kafka-topics.sh --bootstrap-server localhost:$$KAFKA_LISTENER_PORT --list || true clean: @echo \"WARNING: This will stop Kafka + Zookeeper and DELETE docker-volume data.\" @read -p \"Continue? (y/N) \" ans; \\ if [ \"$$ans\" = \"y\" ] || [ \"$$ans\" = \"Y\" ]; then \\ $(DC) down; \\ rm -rf docker-volume/kafka docker-volume/zookeeper; \\ echo \"Data removed.\"; \\ else \\ echo \"Aborted.\"; \\ fi Key points: Uses PROJECT_NAME so this stack doesn‚Äôt clash with others. init: Copies .env.example ‚Üí .env (one-time). Creates docker-volume/ folders. Pulls and builds i","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:5:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"modules/kafka/scripts/test_health.sh #!/usr/bin/env bash set -euo pipefail ENV_FILE=\"${1:-.env}\" if [ ! -f \"$ENV_FILE\" ]; then echo \"Env file '$ENV_FILE' not found. Run 'make init' first.\" exit 1 fi # Load env (ignore comments / empty lines) # shellcheck disable=SC2046 export $(grep -v '^\\s*#' \"$ENV_FILE\" | grep -v '^\\s*$' | xargs) KAFKA_CONTAINER_NAME=\"${KAFKA_CONTAINER_NAME:-kafka-broker}\" ZOOKEEPER_CONTAINER_NAME=\"${ZOOKEEPER_CONTAINER_NAME:-zookeeper-bank}\" KAFKA_LISTENER_PORT=\"${KAFKA_LISTENER_PORT:-9092}\" ZOOKEEPER_CLIENT_PORT=\"${ZOOKEEPER_CLIENT_PORT:-2181}\" echo \"Using containers:\" echo \" Kafka : ${KAFKA_CONTAINER_NAME} (port ${KAFKA_LISTENER_PORT})\" echo \" Zookeeper : ${ZOOKEEPER_CONTAINER_NAME} (port ${ZOOKEEPER_CLIENT_PORT})\" echo # -------- Healthcheck: container state -------- check_container_health() { local name=\"$1\" local label=\"$2\" local status status=$(docker inspect --format='{{.State.Health.Status}}' \"$name\" 2\u003e/dev/null || echo \"no_healthcheck\") if [ \"$status\" = \"healthy\" ]; then echo \"[OK] $label container health: $status\" elif [ \"$status\" = \"no_healthcheck\" ]; then echo \"[WARN] $label container has no Docker healthcheck. Skipping health status check.\" else echo \"[ERROR] $label container health: $status\" echo \"Hint: docker logs $name\" exit 1 fi } echo \"Checking Docker health status...\" check_container_health \"$ZOOKEEPER_CONTAINER_NAME\" \"Zookeeper\" check_container_health \"$KAFKA_CONTAINER_NAME\" \"Kafka\" echo # -------- Zookeeper sanity: ruok -------- echo \"Running Zookeeper sanity check (ruok)...\" docker exec -i \"$ZOOKEEPER_CONTAINER_NAME\" \\ bash -c \"echo ruok | nc localhost ${ZOOKEEPER_CLIENT_PORT} || exit 1\" | grep -q \"imok\" \\ \u0026\u0026 echo \"[OK] Zookeeper responded with 'imok'\" \\ || { echo \"[ERROR] Zookeeper did not respond with 'imok'\"; exit 1; } echo # -------- Kafka sanity: list topics -------- echo \"Running Kafka topic list sanity check...\" docker exec -i \"$KAFKA_CONTAINER_NAME\" \\ kafka-topics.sh --bootstrap-server \"localhost:${KAFKA_LISTENER_PORT}\" --list || { echo \"[ERROR] Failed to list Kafka topics.\" exit 1 } echo \"[OK] Kafka topic list command executed successfully.\" echo echo \"Health + smoke checks completed successfully.\" Notes: Expects (in .env): KAFKA_CONTAINER_NAME (optional, defaults to kafka-broker) ZOOKEEPER_CONTAINER_NAME (optional, defaults to zookeeper-bank) KAFKA_LISTENER_PORT (optional, defaults to 9092) ZOOKEEPER_CLIENT_PORT (optional, defaults to 2181) If your actual container names differ, either: Set them in .env, e.g.: KAFKA_CONTAINER_NAME=kafka-broker ZOOKEEPER_CONTAINER_NAME=zookeeper-bank Or adjust defaults at the top of the script. Zookeeper check: uses ruok ‚Üí expects imok. Kafka check: lists topics via kafka-topics.sh inside the broker container. Finally: chmod +x modules/kafka/scripts/test_health.sh üß≠ Real-World Readiness This new Kafka module is now: Production-friendly Debuggable in real time Observable with JMX exporter Independent for multi-team reuse Mapped directly to Kubernetes / OpenShift patterns The separate Dockerfiles reflect how teams package infra images in real enterprises. You now have a Kafka module that belongs in a real system ‚Äî not just a tutorial. üìù Summary of Part 2 You now have a: Custom Kafka image with debugging tools Custom Zookeeper image with debugging tools Prometheus-ready Kafka JMX metrics Topic initialization script modeling realistic event domains Standardized Makefile and folder structure Canonical docker-volume/ layout Deterministic and reusable Kafka Infra Module This is the Kafka every backend platform team wishes they had ready to go. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:6:0","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"GitHub Repository Link üîó Project Repo: https://github.com/KathiravanMuthaiah/infrastructureWithDocker ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:6:1","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"Building Infrastructure with Docker Series: post links üîó Building Infrastructure with Docker ‚Äî Part0: üîó Building Infrastructure with Docker ‚Äî Part1: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part2/:6:2","tags":["kafka","zookeeper","docker","devops","observability","infra-modules","jmx","event-streaming"],"title":"Building Infrastructure with Docker ‚Äî Part 2: Kafka + Zookeeper","uri":"/posts/building_infrastructure_with_docker_part2/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"Part 1 of the Docker Infrastructure Series dives into building a reusable, isolated, production-grade PostgreSQL infrastructure module with deterministic behaviour, health checks, pinned images, and Makefile-driven lifecycle.","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"üóÑÔ∏è Building Infrastructure with Docker ‚Äî Part 1 ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:0:0","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"PostgreSQL: A Reusable, Independent Database Module Welcome to Part 1 of the Building Infrastructure with Docker series. In Part-0, we set the foundation: one mono-repo, multiple fully independent modules, each engineered with deterministic behaviour, pinned container images, self-contained docs, health checks, and Makefile-driven execution. We now begin the first real module in the series ‚Äî PostgreSQL. This module is intentionally simple but extremely important: every other module in this series that interacts with a relational database or requires CDC (Change Data Capture using Debezium later) will rely on the principles we establish here. Our goal is not to ‚Äúrun PostgreSQL in Docker.‚Äù Our goal is to engineer a reusable infrastructure component you can plug into any project. üéØ What We Are Building in Part 1 This module provides a standalone PostgreSQL instance inside the repository under: infra-docker-series/modules/postgres/ Once built, this module: Runs independently using make up Provides health checks using pg_isready Stores data consistently under docker-volume/data/ Uses pinned Docker image versions (no latest) Exposes a simple smoke test (SELECT 1) Can be reused across any other project you build If you learn the pattern here, every future module will feel natural. 1. üß± Folder Structure ‚Äî Postgres Module Inside the mono-repo, the PostgreSQL module lives here: modules/ postgres/ docs/ README.md requirements.md design-intent.md diagrams/ infra/ docker-compose.yml docker-volume/ data/ scripts/ test_health.sh .env.example Makefile Jenkinsfile This layout is the canonical scaffold for the entire series. Kafka, Mosquitto, Keycloak, Prometheus, and all future parts will follow this identical pattern. üß© The Architecture (Simple but as-is) Data is bind-mounted locally (not named volumes) A dedicated Docker network postgres_net isolates traffic Everything is driven by environment variables loaded from .env This keeps it production-minded while still very easy to work with. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:1:0","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2. PostgreSQL module files All paths below are relative to: infra-docker-series/modules/postgres/ ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:0","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.1 modules/postgres/.env.example # Postgres container settings POSTGRES_CONTAINER_NAME=infra_postgres POSTGRES_DB=app_db POSTGRES_USER=app_user POSTGRES_PASSWORD=change_me_locally POSTGRES_PORT=5432 # Image version pin POSTGRES_VERSION=15 You will copy this to .env manually and adjust POSTGRES_PASSWORD etc. .env should be gitignored (already covered by root .gitignore). ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:1","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.2 modules/postgres/infra/docker-compose.yml version: \"3.9\" services: postgres: image: postgres:${POSTGRES_VERSION} container_name: ${POSTGRES_CONTAINER_NAME} restart: unless-stopped environment: POSTGRES_DB: ${POSTGRES_DB} POSTGRES_USER: ${POSTGRES_USER} POSTGRES_PASSWORD: ${POSTGRES_PASSWORD} PGDATA: /var/lib/postgresql/data/pgdata ports: - \"${POSTGRES_PORT}:5432\" volumes: - ../docker-volume/data:/var/lib/postgresql/data healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB\"] interval: 10s timeout: 5s retries: 5 start_period: 15s networks: - postgres_net networks: postgres_net: name: postgres_net driver: bridge Notes: Volume path ../docker-volume/data is relative to infra/, mapping to docker-volume/data at module root. Image pinned via POSTGRES_VERSION env, defaulting to 15. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:2","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.3 modules/postgres/Makefile (module-level) # PostgreSQL module Makefile COMPOSE_FILE := infra/docker-compose.yml DOCKER_COMPOSE := docker compose -f $(COMPOSE_FILE) ENV_FILE ?= .env .PHONY: help init up down logs test clean psql help: @echo \"PostgreSQL module\" @echo \"Targets:\" @echo \" init - prepare env and folders\" @echo \" up - start postgres container\" @echo \" down - stop postgres container\" @echo \" logs - tail container logs\" @echo \" test - run health/smoke test\" @echo \" clean - stop and remove data after confirmation\" @echo \" psql - open psql shell into the database\" init: @if [ ! -f \"$(ENV_FILE)\" ]; then \\ echo \"Creating $(ENV_FILE) from .env.example\"; \\ cp .env.example $(ENV_FILE); \\ else \\ echo \"$(ENV_FILE) already exists, skipping copy.\"; \\ fi @mkdir -p docker-volume/data @echo \"Pulling images...\" @$(DOCKER_COMPOSE) --env-file $(ENV_FILE) pull up: @$(DOCKER_COMPOSE) --env-file $(ENV_FILE) up -d down: @$(DOCKER_COMPOSE) --env-file $(ENV_FILE) down logs: @$(DOCKER_COMPOSE) --env-file $(ENV_FILE) logs -f test: @./scripts/test_health.sh $(ENV_FILE) clean: @read -p \"This will stop the container and DELETE docker-volume/data. Continue? (y/N) \" ans; \\ if [ \"$$ans\" = \"y\" ] || [ \"$$ans\" = \"Y\" ]; then \\ $(DOCKER_COMPOSE) --env-file $(ENV_FILE) down; \\ rm -rf docker-volume/data; \\ echo \"Data directory removed.\"; \\ else \\ echo \"Aborted.\"; \\ fi psql: @./scripts/test_health.sh $(ENV_FILE) --psql ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:3","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.4 modules/postgres/scripts/test_health.sh #!/usr/bin/env bash set -euo pipefail ENV_FILE=\"${1:-.env}\" MODE=\"${2:-health}\" if [ ! -f \"$ENV_FILE\" ]; then echo \"Env file '$ENV_FILE' not found. Run 'make init' first.\" exit 1 fi # shellcheck disable=SC2046 export $(grep -v '^\\s*#' \"$ENV_FILE\" | xargs) CONTAINER_NAME=\"${POSTGRES_CONTAINER_NAME:-infra_postgres}\" echo \"Using container: ${CONTAINER_NAME}\" echo \"Checking health status...\" HEALTH_STATUS=$(docker inspect \\ --format='{{.State.Health.Status}}' \\ \"${CONTAINER_NAME}\" 2\u003e/dev/null || echo \"not_found\") if [ \"$HEALTH_STATUS\" != \"healthy\" ]; then echo \"Container health status: ${HEALTH_STATUS}\" echo \"Hint: check logs with 'make logs' or 'docker logs ${CONTAINER_NAME}'\" exit 1 fi echo \"Container is healthy.\" if [ \"$MODE\" = \"--psql\" ]; then echo \"Opening psql shell...\" docker exec -it \"${CONTAINER_NAME}\" \\ psql -U \"${POSTGRES_USER}\" -d \"${POSTGRES_DB}\" exit 0 fi echo \"Running smoke test: SELECT 1;\" docker exec -i \"${CONTAINER_NAME}\" \\ psql -U \"${POSTGRES_USER}\" -d \"${POSTGRES_DB}\" \\ -c \"SELECT 1;\" \u003e/dev/null echo \"Smoke test passed.\" Make sure to chmod +x modules/postgres/scripts/test_health.sh. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:4","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.5 modules/postgres/docs/README.md # PostgreSQL Infrastructure Module This module provides a reusable PostgreSQL instance running in Docker with: - Pinned PostgreSQL version (configured via `.env`). - Local bind-mounted storage under `docker-volume/data`. - Healthcheck configuration. - Makefile-driven lifecycle (`init`, `up`, `test`, `down`, `clean`). - Simple smoke test using `psql` (`SELECT 1`). ## Quick Start ```bash # From repo root cd modules/postgres # Prepare env and pull images make init # Start PostgreSQL make up # Run health and smoke test make test # Optional: open psql shell into the DB make psql # Stop PostgreSQL make down Data is stored under modules/postgres/docker-volume/data and persists across restarts. Use make clean to remove it after confirmation. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:5","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.6 modules/postgres/docs/requirements.md # PostgreSQL Module ‚Äì Requirements ## Business / Functional Intent - Provide a standalone PostgreSQL instance that can be: - Started and stopped via Makefile and Docker Compose. - Reused across multiple application projects. - Used as the source database for future modules (e.g., Debezium CDC). - Keep the module self-contained so it can be cloned and used without the rest of the series. ## Non-Functional Requirements - Deterministic setup: - Explicit PostgreSQL image version (no `latest`). - Single, documented port with override capability via `.env`. - Persistence: - Data stored under `docker-volume/data` inside the module. - Safe cleanup via `make clean` only after explicit confirmation. - Observability: - Docker healthcheck using `pg_isready`. - Smoke test using `psql` (`SELECT 1`). - Security: - Credentials defined in `.env` (not committed). - `.env.example` provided for reference. - Portability: - No external dependencies beyond Docker and Docker Compose. - No hard-coded host paths; everything relative to the module root. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:6","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.7 modules/postgres/docs/design-intent.md # PostgreSQL Module ‚Äì Design Intent ## Overview This module provides a single PostgreSQL instance intended as: - A reusable DB for local development. - A base for CDC experiments (e.g., with Debezium in another module). - A template for how other infrastructure modules in this series are structured. ## Architecture ```mermaid flowchart LR dev[Developer] --\u003e docker[Docker Engine] docker --\u003e compose[Docker Compose] compose --\u003e pg[PostgreSQL Container] pg --\u003e vol[docker-volume data] docker-compose.yml defines a single postgres service. Data directory is bind-mounted from docker-volume/data. A dedicated Docker bridge network postgres_net isolates traffic. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:7","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"2.8 modules/postgres/Jenkinsfile (skeleton) pipeline { agent any environment { MODULE_DIR = \"modules/postgres\" } stages { stage('Checkout') { steps { checkout scm } } stage('Init') { steps { dir(MODULE_DIR) { sh 'make init' } } } stage('Up') { steps { dir(MODULE_DIR) { sh 'make up' } } } stage('Test') { steps { dir(MODULE_DIR) { sh 'make test' } } } stage('Down') { steps { dir(MODULE_DIR) { sh 'make down' } } } } post { always { script { try { dir(MODULE_DIR) { sh 'make down || true' } } catch (err) { echo \"Cleanup failed: ${err}\" } } } } } This is just a reference Jenkins skeleton file, not yet complete. leaving Jenkins out of scope for this series. 3.‚öôÔ∏è Core Configuration The PostgreSQL behaviour is driven by .env.example, which you copy into .env: POSTGRES_DB=app_db POSTGRES_USER=app_user POSTGRES_PASSWORD=change_me_locally POSTGRES_PORT=5432 POSTGRES_VERSION=15 Why this matters: You can change the port without editing the compose file. You can rotate credentials without committing secrets. You can upgrade PostgreSQL by adjusting a single version variable. This reflects real-world configuration hygiene. 4. üêò docker-compose.yml ‚Äî Pinned, Predictable, Safe The module‚Äôs docker-compose.yml pins PostgreSQL to a specific version: image: postgres:${POSTGRES_VERSION} and sets a solid health check: healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB\"] interval: 10s timeout: 5s retries: 5 start_period: 15s The container is only considered ready when PostgreSQL is truly accepting connections. This tiny decision prevents unpredictable behavior in downstream systems‚Äîsomething every engineer learns the hard way at least once. 5. üîß Makefile-Driven Lifecycle Every module in this series uses the same Makefile contract: Command What It Does make init Creates .env, prepares folders, pulls images make up Starts the PostgreSQL container make test Health check + smoke test (SELECT 1) make down Stops the service make clean Stops service + removes data (with confirmation) make psql Opens an interactive shell inside PostgreSQL You can run it inside the module: cd modules/postgres make init make up make test make psql make down Or from the root of the repo: make init MODULE=postgres make up MODULE=postgres make test MODULE=postgres This uniform experience across all modules is the core training aspect of this series. 6. ü©∫ Smoke Test: Trust, but Verify After make up, you run: make test This executes test_health.sh which: Checks Docker health status ‚Üí must be healthy Runs: SELECT 1; via psql inside the container. If both succeed, your PostgreSQL module is considered operational. If either fails, logs are suggested: make logs This one minute test ensures your infra module isn‚Äôt just ‚Äúrunning‚Äù‚Ä¶ ‚Ä¶it‚Äôs actually working. 7. üíæ Persistence Strategy Your data lives here: modules/postgres/docker-volume/data/ This folder: is bind-mounted (not named volume) is owned by this module only is always safe to delete manually if needed is ignored from Git by default This approach: Lets you snapshot/copy/backup easily Ensures no global Docker volumes pollute your system Keeps module state self-contained Exactly how enterprise infra-as-code teams work. 8. üß™ Real-World Deployment Notes (Quick) Even though this module runs locally: The same Docker Compose file becomes your base for Kubernetes StatefulSets. .env values map to Kubernetes Secrets and ConfigMaps. docker-volume/data maps to PersistentVolumeClaims. Healthchecks translate to liveness/readiness probes. This is deliberate. This series trains you for real production patterns, not just local demos. 9. ‚ö†Ô∏è Common Pitfalls (and How We Avoid Them) Pitfall How This Module Prevents It Using latest image Version pinned in .env.example Global Docker volumes Local bind-mount inside module only Weak health checks pg_isready validates actual DB readiness Secrets committed to git .env ignored, .env.example only Data loss on tear-down make clean requires explicit confirmation Non-repeatable setup Dete","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:8","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"GitHub Repository Link üîó Project Repo: https://github.com/KathiravanMuthaiah/infrastructureWithDocker ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:9","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Infrastructure","Docker Series"],"content":"Building Infrastructure with Docker Series: post links üîó Building Infrastructure with Docker ‚Äî Part0: üîó Building Infrastructure with Docker ‚Äî Part2: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part1/:2:10","tags":["docker","postgresql","infrastructure-module","devops","reusable-infrastructure","database-engineering"],"title":"Building Infrastructure with Docker ‚Äî Part 1: PostgreSQL","uri":"/posts/building_infrastructure_with_docker_part1/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"Kickstarting a hands-on series on building reusable, production-grade infrastructure modules with Docker ‚Äî starting from PostgreSQL to Kafka, Prometheus, and beyond.","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üß± Building Infrastructure with Docker ‚Äî Part 0 ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:0:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"The Journey to Reusable, Independent Infrastructure Modules When you start a new project, how many times do you rebuild the same supporting infrastructure ‚Äî a database, a message broker, a cache, a monitoring stack ‚Äî before writing your first line of application logic? Most engineers do it every single time. This series aims to end that cycle. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:0:1","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üí° Why This Series Exists We‚Äôre going to create a library of self-contained, production-grade infrastructure projects, each running in Docker and built to be reused across any system. Each infrastructure component ‚Äî PostgreSQL, Kafka, Mosquitto (MQTT), Keycloak, Prometheus, Grafana, Jaeger, MongoDB, Ignite, and Debezium ‚Äî will live in its own independent project, with deterministic builds and persistent local volumes. By the end of this series, you‚Äôll be able to: Run any of these infrastructures independently. Combine them into a working data flow (for example: MQTT ‚Üí Kafka ‚Üí PostgreSQL ‚Üí Debezium ‚Üí Grafana). Understand how each component fits into real-world enterprise systems. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:1:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"‚öôÔ∏è Our Philosophy This is not another ‚Äúrun this Docker command‚Äù tutorial. We‚Äôll treat each infrastructure component with the same engineering discipline used in production environments: Principle What It Means in Practice Isolation Each component lives in its own repo and can be run independently. Determinism No latest tags ‚Äî all images are pinned to tested versions. Persistence All data is stored under ./docker-volume/ inside each project. Transparency No hidden scripts. Everything runs through Makefile targets. Security .env.example is versioned; real secrets stay local. Observability Every container includes a healthcheck and basic metrics endpoint. If you follow along, you‚Äôll learn not just how to run infra, but how to engineer it right. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:2:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üß© The Architecture We‚Äôll Build (Concept) At a high level, we are building an event telemetry pipeline that passes through several layers of infrastructure. Each component will be implemented and validated one at a time. Later in the series, we will show small, optional integration examples that stitch these modules together ‚Äî without breaking their independence. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:3:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üß± Series Roadmap Part Topic Focus 0 Introduction \u0026 Project Layout (this post) ‚Äì goals, repo structure, workflow 1 PostgreSQL persistent DB, healthcheck, seed DDL 2 Kafka + Zookeeper message backbone 3 Mosquitto MQTT lightweight telemetry broker 4 Debezium change-data-capture from Postgres 5 Keycloak authentication: UI login + API tests via curl 6 Prometheus scraping metrics and targets 7 Grafana dashboards and provisioning 8 Jaeger distributed tracing 9 MongoDB document store basics 10 Apache Ignite in-memory data grid with persistence 11 Node Exporter + cAdvisor system and container metrics 12 Putting It All Together simple telemetry-to-dashboard demo Each part will come with runnable code and configuration inside a single Git repository. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:4:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üìÇ How the Git Repository Is Organised All modules in this series live in one repo, but each module stays isolated inside its own folder under modules/. A simplified view of the parent project structure: infra-docker-series/ README.md Makefile docs/ part-0.md roadmap.md tooling/ mk/ common.mk scripts/ subtree-export.sh modules/ postgres/ ... PostgreSQL-specific content (Part 1) ... kafka/ ... Kafka-specific content (Part 2) ... mosquitto/ ... Mosquitto-specific content (Part 3) ... keycloak/ ... Keycloak module (Part 5) ... debezium/ ... Debezium module (Part 4) ... prometheus/ ... Prometheus module (Part 6) ... grafana/ ... Grafana module (Part 7) ... jaeger/ ... Jaeger module (Part 8) ... mongodb/ ... MongoDB module (Part 9) ... ignite/ ... Ignite module (Part 10) ... node-exporter-cadvisor/ ... metrics helper module (Part 11) ... orchestration/ README.md snippets/ ... small integration examples (later in the series) ... ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:5:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"What you need to know as a reader You only need this one repository for the entire series. Every infrastructure piece lives in a separate folder under modules/. Each module will have its own: infra/docker-compose.yml docker-volume/ directory for data Makefile with standard targets (init, up, test, down, clean) docs/ with module-specific notes We will design and explain each module‚Äôs inner structure in its own part of the series. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:5:1","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üß∞ Root Makefile: A Simple Entry Point The root Makefile exists only to make your life easier. It does not run any combined stack on its own; it just forwards commands to individual modules. Typical usage from the root of the repo: # List available modules make list # Bring up a specific module (for example, PostgreSQL) make up MODULE=postgres # Run its smoke tests make test MODULE=postgres # Tear it down make down MODULE=postgres Internally, this just runs make inside modules/postgres/ (or whatever module you choose). Each module still has its own Makefile and can be used directly from its folder if you prefer. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:6:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üß± Inside a Module (High-Level View) In later parts, we will deep dive into each infrastructure module and define its full structure. For now, this is the high-level pattern each module will follow: modules// docs/ README.md requirements.md design-intent.md infra/ docker-compose.yml docker-volume/ ... data, bind-mounted ... scripts/ test_health.sh .env.example Makefile Jenkinsfile .gitignore You will see concrete content starting from Part 1 (PostgreSQL). The key point now: all modules share the same shape and workflow, so once you learn one, the others feel familiar. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:7:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üßë‚Äçüíª How You Will Work With This Repo Clone the repository once: git clone https://github.com//infra-docker-series.git cd infra-docker-series See what modules exist: make list Pick a module and work in isolation: make init MODULE=postgres make up MODULE=postgres make test MODULE=postgres make down MODULE=postgres When we introduce new modules (Kafka, Mosquitto, Keycloak, etc.), you will follow the same pattern, simply changing MODULE=\u003cname\u003e. Later in the series, we will add optional orchestration snippets under orchestration/ that show how to connect multiple modules together. These will be off by default so that modules remain clean and independent. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:8:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üß≠ Learning Philosophy and Workflow For every module, we follow the same three-phase approach: Design Explain the purpose of the module. Decide image versions, ports, environment variables. Document everything in docs/requirements.md and docs/design-intent.md. Build Write infra/docker-compose.yml with pinned image tags. Add a Makefile with init, up, test, down, clean. Prepare .env.example for configuration. Test Implement scripts/test_health.sh. Run a small, meaningful smoke test: PostgreSQL: SELECT 1 Kafka: produce/consume a message Mosquitto: mosquitto_pub / mosquitto_sub Keycloak: Login and call a protected API Validate logs and cleanup. If you follow these steps with each part, you will build the same discipline in your own projects. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:9:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"‚ö†Ô∏è Pitfalls We Intentionally Avoid Putting everything into one giant docker-compose file ‚Üí Hard to reason about, hard to test in isolation. We keep each infrastructure module separate. Using latest tags ‚Üí Leads to surprising upgrades and broken setups. We always pin explicit versions per module. Mixing app code with infra ‚Üí Infrastructure from this repo can be reused in multiple applications. Applications live elsewhere; this repository focuses on infra only. Committing secrets ‚Üí We version .env.example only. Your real .env stays on your machine and is .gitignored. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:10:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üîú Coming Up Next ‚Äî Part 1: PostgreSQL We‚Äôll begin with the most fundamental component ‚Äî PostgreSQL. You‚Äôll learn how to: Pin a specific image version. Bind a local persistent volume under ./docker-volume/postgres/data. Add a startup healthcheck. Seed a schema and validate connectivity using psql. Clean up safely with make down. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:11:0","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"üìò Final Thoughts This series isn‚Äôt about copying commands ‚Äî it‚Äôs about thinking like an infrastructure engineer. By the end, you won‚Äôt just know how to ‚Äúrun Docker,‚Äù you‚Äôll understand how to build and maintain reliable infrastructure stacks that scale from your laptop to production. Let‚Äôs begin. ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:11:1","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"GitHub Repository Link üîó Project Repo: https://github.com/KathiravanMuthaiah/infrastructureWithDocker ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:11:2","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Engineering","Docker","Infrastructure"],"content":"Building Infrastructure with Docker Series: post links üîó Building Infrastructure with Docker ‚Äî Part1: üîó Building Infrastructure with Docker ‚Äî Part2: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-12-07","objectID":"/posts/building_infrastructure_with_docker_part0/:11:3","tags":["docker","infrastructure","devops","kafka","postgresql","prometheus","grafana","keycloak","debezium"],"title":"Building Infrastructure with Docker ‚Äî part 0","uri":"/posts/building_infrastructure_with_docker_part0/"},{"categories":["Reflections","City Life"],"content":"A quiet reflection on an ordinary city evening that revealed the beauty of companionship after a long, tiring day.","date":"2025-11-28","objectID":"/posts/a_beautiful_evening/","tags":["evening","relationships","companionship","urban reflections","life moments"],"title":"A Beautiful Evening","uri":"/posts/a_beautiful_evening/"},{"categories":["Reflections","City Life"],"content":"A Beautiful Evening In the middle of a busy city evening, just as the long weekend began to breathe into the air, a moment caught my attention. A man was walking slowly, his steps relaxed yet heavy, his shoulders gently slouched from a long, tiring day. The signs of exhaustion were clear ‚Äî the weight of work still hanging on him even as he drifted away from it. But there was something deeper in the picture. Despite the fatigue, there was a quiet happiness on his face. A large ladies‚Äô handbag rested on one shoulder, and on the other side, his wife held his hand with confident warmth. His steps wandered, almost aimless, but never lost ‚Äî as if her presence anchored him. The comfort of that steady partner beside him gave him the energy he had spent all day earning. In that simple walk, the moment spoke aloud: the long day was worth it, the effort meaningful, because this ‚Äî this companionship, this calm escape, this shared journey ‚Äî is the reward. ‚Äî Kathiravan Muthaiah Technically authored by me, with insights assisted by ChatGPT. ","date":"2025-11-28","objectID":"/posts/a_beautiful_evening/:0:0","tags":["evening","relationships","companionship","urban reflections","life moments"],"title":"A Beautiful Evening","uri":"/posts/a_beautiful_evening/"},{"categories":["Reflections","Personal","Life Lessons"],"content":"Reflections on a 5-year journey showing how relationships define the true value of time, health, and personal growth.","date":"2025-09-13","objectID":"/posts/reflections_from_the_journey/","tags":["relationships","time","health","value of relationships","life lessons","personal growth","self-reflection","journey"],"title":"Relationships: The Hidden Dimension of Time and Health","uri":"/posts/reflections_from_the_journey/"},{"categories":["Reflections","Personal","Life Lessons"],"content":"Relationships: The Hidden Dimension of Time and Health ","date":"2025-09-13","objectID":"/posts/reflections_from_the_journey/:0:0","tags":["relationships","time","health","value of relationships","life lessons","personal growth","self-reflection","journey"],"title":"Relationships: The Hidden Dimension of Time and Health","uri":"/posts/reflections_from_the_journey/"},{"categories":["Reflections","Personal","Life Lessons"],"content":"The Journey The moments I wanted to dedicate to a few relationships, I choose to capture through this blog ‚Äî a timeless space where they can live forever. From the year 2020 until today (mid-2025), it has been nothing short of a thrill ride. I stepped away from what many considered the ‚Äúsafe job‚Äù in MNC life, moved to a small town with a different thought process, then lived through the rush of a high-paced startup, shifted into a tech-nomad (consultant) life and finally returned to an MNC in 2025. This has been more than a career shift; it has been a journey of constant learning ‚Äî not only about technology but about myself, my relationships, and my values. Ironically, I learned more technology in these five years than I did in the previous eighteen years, but what stayed with me more deeply were the lessons about time, health, and the irreplaceable dimension of relationships. ","date":"2025-09-13","objectID":"/posts/reflections_from_the_journey/:0:1","tags":["relationships","time","health","value of relationships","life lessons","personal growth","self-reflection","journey"],"title":"Relationships: The Hidden Dimension of Time and Health","uri":"/posts/reflections_from_the_journey/"},{"categories":["Reflections","Personal","Life Lessons"],"content":"Reflections from the Journey At first, I believed success and happiness were all about timing it right and finding the right balance. And for some time, that seemed true ‚Äî the sweet spots appeared, career growth happened, and the journey felt rewarding. But as the years passed, I realized that life is not always about timing or balance. It tests us against our principles and values more often than we expect. I began to see the shades of grey ‚Äî moments when values fade, or when principles are risked even for a short while. The guilt and anger of those compromises linger longer than the events themselves. Over time, I came to understand: there is no such thing as ‚Äútiming it right‚Äù or always finding the perfect balance. What truly matters is how we see, observe, and listen, and how well we have equipped ourselves early in life to face the shades of grey. My humble submission is this: if we can be satisfied that we gave our full effort, reason out with ourselves that the outcome is natural, and not dwell in perceptions of ‚Äúfair‚Äù or ‚Äúunfair,‚Äù then we are already successful in our path. Through all of this, one constant has stood out to me: the immense joy of being surrounded by people you truly want to be with. Beyond career, beyond achievements, the most enduring realization is simple ‚Äî to be valued in someone‚Äôs life and to value them in return is the best definition of a successful life. ","date":"2025-09-13","objectID":"/posts/reflections_from_the_journey/:0:2","tags":["relationships","time","health","value of relationships","life lessons","personal growth","self-reflection","journey"],"title":"Relationships: The Hidden Dimension of Time and Health","uri":"/posts/reflections_from_the_journey/"},{"categories":["Reflections","Personal","Life Lessons"],"content":"A Note of Gratitude This part is my contribution to a few people without mentioning names ‚Äî not out of secrecy, but out of respect for privacy and to avoid unintentionally missing someone. I have always liked the concept of angels. They are not born with wings ‚Äî but in certain moments, we realize they exist. I am glad and grateful that I have been surrounded by such angels throughout this journey. One of them I met for only a few hours a day, over just three days, in a very limited professional space. Yet those moments helped me understand myself more deeply and left a lasting impression. That person became a mentor, and through him, I was introduced to another mentor both continues to amaze me ‚Äî showing me that regardless of age, money, profession, or social standing, wisdom and guidance can shine through. These mentors have been a guiding light in ways I cannot put into words. Then, there are family and friends ‚Äî the ones we too often take for granted. They are always there to rely on, yell at, fight with, frown at, and even ignore at times. But beneath all that, they remain the unshakable pillars of daily life. This doesn‚Äôt mean I have been ‚Äúcleansed‚Äù or transformed into a perfectly behaved person. I remain human, with my same quirks and traits. The difference is that I now try harder to reciprocate the unconditional guardrails they provide ‚Äî the support that keeps my journey safe today, tomorrow, and for however long it continues. ","date":"2025-09-13","objectID":"/posts/reflections_from_the_journey/:0:3","tags":["relationships","time","health","value of relationships","life lessons","personal growth","self-reflection","journey"],"title":"Relationships: The Hidden Dimension of Time and Health","uri":"/posts/reflections_from_the_journey/"},{"categories":["Reflections","Personal","Life Lessons"],"content":"Worth the try The more we learn arts and science, the more differently we see life. It is art that evokes the deepest emotions ‚Äî songs, stories, movie scenes, or simple anecdotes that stir something inside us. Science may still be working to explain how these experiences shape our biology, but I have felt it many times: art heals, art triggers, art sustains. In moments when I was less active or unable to do much, I found myself listening more, reading more, and letting these pieces of art fill the silence. They always brought back memories ‚Äî treasured times when I could act, feel, and share with others. Those moments were never about the activity alone; they were about the presence of another life form in that space. When I reflect deeply, I see why those memories are so special. They combine the time we had, the health that allowed us to act, and most importantly, the relationships that made the moment meaningful. Science may one day achieve time travel, allowing us to revisit moments in time. But even then, reality will remind us: the relationships that made those moments alive cannot be retrieved once lost. Without them, time is hollow, and health is just survival. So let us not only count the years but qualify them with the richness of relationships. Let us cherish each and every moment with loved ones, so that when we look back, we can say we created a life that mattered ‚Äî not just a long life, but a meaningful one. To enjoy the time, music is one of the best way that too if reading alone. Sharing one such art helped me during the reflection: Watch on YouTube Same feeling but another reflection Watch on YouTube If you watch the link, you will see both have same intentions and share similar views. But journey and reflections created on each mind is much varied to equate mathematically. Similarly each of our path, journey and relationships are unique and let us cherish those. Technically authored by me, with insights assisted by ChatGPT. Happy Learning! ","date":"2025-09-13","objectID":"/posts/reflections_from_the_journey/:0:4","tags":["relationships","time","health","value of relationships","life lessons","personal growth","self-reflection","journey"],"title":"Relationships: The Hidden Dimension of Time and Health","uri":"/posts/reflections_from_the_journey/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"Explore how morally sensitive children express fairness and truth, and how society can nurture their voice of principle into confident leadership.","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"Discovery of Young Minds: Nurturing the Voice of Principle in Children üß†‚ú® ‚ÄúSome children feel truth deeper than others ‚Äî not stubbornness, but leadership in the making.‚Äù ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:0:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"Introduction Every child is born with a unique lens to view the world. Some children demonstrate a remarkable sense of fairness and truth, noticing errors or injustices around them long before their peers do. They feel compelled to express their thoughts, even when it may invite social friction or risk. Rather than labeling such children as stubborn or defiant, we can recognize them as young minds in discovery ‚Äî minds that carry the seed of future principled leadership. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:0:1","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"1. The Inner World of Young Minds Children with strong moral awareness experience a rich and sometimes turbulent inner world: Inner Process Child‚Äôs Experience Heightened Observation Quickly notices unfairness, mistakes, or contradictions. Inner Conflict Feels mental discomfort when the world doesn‚Äôt match their value system. Compulsive Expression Feels a pressing urge to express or correct to find inner relief. Relief vs. Risk Expression provides relief, but can lead to social friction or misunderstanding. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:1:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"Illustrative Example A 9-year-old sees a teacher misstate a historical fact. Impulse: Immediately corrects the teacher. Outcome: Class laughs, teacher scolds, child feels misunderstood. Internal Effect: Replays the incident at home, feeling guilt for staying silent in future or shame for speaking out. This is a discovery moment ‚Äî the child is navigating the tension between inner truth and social adaptation. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:1:1","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"2. Why This Behaviour Emerges Cognitive Sharpness High IQ or advanced pattern recognition triggers early moral reasoning. Early Value Imprinting Raised with absolute moral instructions like ‚Äúalways tell the truth‚Äù without nuance. Emotional Sensitivity Strong empathy makes unfairness or errors emotionally heavy. Limited Social Tools Lacks guidance on how to express truth safely and effectively. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:2:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"3. The Path of Nurturing: From Inner Turmoil to Empowered Expression Instead of suppressing or punishing, children need guidance and safe spaces to channel their inner moral compass. Supporter Role in Empowerment Parents Validate feelings, teach timing and context for truth-telling. Teachers Provide safe avenues: private discussion, reflection notes, or class ‚Äútruth moments.‚Äù Society Celebrate constructive dissent and normalize emotional intelligence training in schools. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:3:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"Illustration: Positive Path to Empowerment ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:3:1","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"4. Societal Importance of Recognizing Young Minds Unaddressed, these children may experience: Social isolation Overthinking or guilt loops Loss of confidence to speak truth When supported, they can become: Ethical innovators Principled leaders Change agents who balance truth and empathy ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:4:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"5. Real-World Inspiration Many world-renowned leaders started as morally sensitive children: Leader Early Trait Global Impact Mahatma Gandhi Refusal to accept injustice Led India‚Äôs independence with non-violence Nelson Mandela Deep moral courage from youth Dismantled apartheid, inspired reconciliation Malala Yousafzai Spoke truth about girls‚Äô education Became a global advocate for education rights Abraham Lincoln Early disdain for unfairness Abolished slavery, reshaped U.S. history Their journey from sensitive child to principled leader shows the power of nurturing inner truth with social wisdom. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:5:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"6. Building a Safe Future for Expression To discover and empower young minds, society must ensure: Homes encourage reflective, not reactive, truth. Schools teach emotional and social intelligence alongside academics. Communities value moral courage, not only compliance. Outcome: A generation that can safely express their feelings, champion fairness, and become tomorrow‚Äôs ethical leaders. ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:6:0","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Parenting","Child Development","Social Awareness"],"content":"Closing Thought Discovery of young minds is not just about observing their brilliance ‚Äî it is about creating a secure environment where their inner compass can grow into principled, empathetic, and confident leadership for the future. Technically authored by me, with insights assisted by ChatGPT. Happy Learning! ","date":"2025-08-28","objectID":"/posts/discovery_of_young_minds/:6:1","tags":["child psychology","moral development","young minds","principled children","mental health","ethical parenting","child behavior","truth-telling","voice of principle"],"title":"Discovery of Young Minds: Nurturing the Voice of Principle in Children","uri":"/posts/discovery_of_young_minds/"},{"categories":["Education","Courses"],"content":"Explore IIT B.Des programs across IIT Bombay, Guwahati, Delhi, Hyderabad, Roorkee, Indore, and IIITDM Jabalpur. Specialisations, seats, eligibility, placements, and a consolidated comparison with tier recommendations for aspirants.","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"IIT BDes Programs awareness material Choosing the right Bachelor of Design (B.Des) program in India is a big decision for aspiring designers. Among the top options, the IIT B.Des programs have quickly gained recognition for blending creativity with engineering, technology, and real-world problem solving. Unlike traditional design schools, the IITs bring a unique advantage ‚Äî access to advanced labs, interdisciplinary research, and strong industry connections. From the legacy program at IIT Bombay (IDC) to the new thematic curriculum at IIT Indore, each IIT offers distinct fields of specialisation, career opportunities, and learning environments. Admissions are conducted through UCEED (Undergraduate Common Entrance Examination for Design), making these programs both competitive and prestigious. This guide provides a detailed institution-wise review, a consolidated comparison matrix, and tier recommendations ‚Äî to help you understand which IIT B.Des program aligns best with your aspirations. Refer the link for detailed view on each institution‚Äôs offered programs : A DeepDive Institute Specialisations Overview Admissions Eligibility Key Opportunities IIT Bombay (IDC) Industrial, Communication, Animation, Interaction, Mobility \u0026 Vehicle Design All streams (via UCEED) Industry roles; dual-degree possible IIT Hyderabad Product, Visual, Spatial, Interaction, UX Design All streams Broad design exposure, diverse career paths IIT Guwahati Industrial, Communication, Ergonomics, Usability, Design Management Only Science (PCM) UX, ergonomics, consultancy IIT Delhi Product \u0026 Visual Design All streams Focused creative roles IIT Roorkee Product, Manufacturing, Ergonomics, UX, Interaction, Visual Design Only Science (PCM) Multidisciplinary design IIITDM Jabalpur Product, Visual, Interaction, Communication, Craft Design Only Science (PCM) Design-tech hybrids IIT Indore (new) Urban Systems, Educational Tech, Healthcare Systems, Sustainable Energy Design Likely UCEED-based; early cohort Innovation-driven, interdisciplinary focus ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:0:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"Opportunities \u0026 Career Paths From IIT design graduates, diverse roles emerge: Product Design UX/UI Design Industrial Design Consultancy Animation \u0026 Game Design Automotive \u0026 Mobility Design Startups \u0026 Entrepreneurship Research \u0026 Academia AI \u0026 Smart Systems Design ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:1:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"Eligibility \u0026 Admission Process ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:2:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"Entrance Exam: UCEED (Undergraduate Common Entrance Examination for Design) Conducted annually by IIT Bombay Open to students across all streams (Science/Arts/Commerce) with Class XII qualification Design Careers 360+15Wikipedia+15Design Careers 360+15 ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:2:1","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"Stream-Specific Eligibility Non-Science (Arts/Commerce): Eligible for IIT Bombay, IIT Delhi, IIT Hyderabad only. Science (PCM): Eligible for IIT Bombay, IIT Delhi, IIT Hyderabad, IIT Guwahati, IIT Roorkee, IIITDM Jabalpur Design Careers 360+6Opasis+6Design Careers 360+6 ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:2:2","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"Seat Matrix 2025‚Äì26 via UCEED centralized counselling: IIT Bombay: 37 seats IIT Delhi: 20 seats IIT Hyderabad: 26 seats IIT Guwahati: 56 seats IIT Roorkee: 20 seats IIITDM Jabalpur:‚ÄØ66 seats SILICA+1Opasis Below is a consolidated, strong comparison matrix of all the IITs (and IIITDM Jabalpur) offering B.Des programs. This will help you compare focus areas, intake, eligibility, and opportunities side by side. ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:2:3","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"Consolidated Comparison ‚Äì IITs \u0026 IIITDM Jabalpur B.Des Programs Institute Seats (approx.) Eligibility (Stream) Core Specialisations Unique Strengths Limitations / Pitfalls Career / Recruiter Highlights IIT Bombay (IDC) 37 All Streams Industrial, Communication, Animation, Interaction, Mobility/Vehicle Legacy school (oldest), widest range, dual-degree (B.Des+M.Des), strong Mumbai industry connect Very high cut-off (UCEED Top ~50), portfolio-driven placements, expensive Mumbai living Recruiters: Google, Adobe, Microsoft, Titan, Tata Motors. Alumni in design leadership roles globally. IIT Guwahati (DoD) 56 Science (PCM) only Industrial, Communication, Ergonomics, Interaction, Design Mgmt Largest batch size, strong ergonomics + usability, serene campus, research-driven Remote location, weaker visual/animation exposure, Arts/Commerce not eligible Recruiters: Adobe, Nutanix, Microsoft, Tata Motors. Strong in UX + ergonomics design. IIT Delhi (DoD) 20 All Streams Product, Visual Compact batch size, Delhi-NCR design/startup hub, social innovation projects New program (started 2022), no long alumni history, limited variety Recruiters: Adobe, Ola Electric, Zomato design, startups. Focus on product + branding. IIT Hyderabad (DoD) 26 All Streams Product, Visual, Spatial, Interaction, UX, Emerging Media Experimental, AR/VR, AI-driven design, strong tie with T-Hub startup ecosystem Still evolving, smaller alumni base, less focus on auto/manufacturing Recruiters: Microsoft, Deloitte, Infosys, Ola Electric, Zomato. Alumni in AR/VR, UX labs. IIT Roorkee (DoD) 20 Science (PCM) only Product, Manufacturing, Ergonomics, UX, Visual Strong engineering‚Äìdesign integration (manufacturing, materials, ergonomics) Small batch, remote location, limited creative media scope Recruiters: Tata Motors, Hero MotoCorp, Adobe, Samsung. Alumni in auto + product design. IIITDM Jabalpur (Design) 66 Science (PCM) only Product, Visual, Interaction, Communication, Craft Largest intake, hybrid design+IT+manufacturing, CAD/CAE strong, craft+tech integration Recruiters skewed to IT services (Infosys/Wipro/TCS Design), creative depth weaker Recruiters: Infosys Design, Wipro, Samsung, Adobe. Alumni in UX, CAD roles. IIT Indore (DoD, New) 15‚Äì20 (first batch) All Streams Urban Systems, Healthcare, Education Tech, Sustainable Energy System-level design focus (health, sustainability, smart cities), aligned to UN SDGs Brand new (2024), no alumni yet, infrastructure still developing, recruiter uncertainty Future scope: Ed-tech, Health-tech, Urban/Sustainability startups. Likely research-focused global pathways. ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:3:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"üîë Insights from the Matrix Legacy \u0026 Brand Strength: IIT Bombay (IDC) ‚Üí strongest legacy, widest range, global alumni. IIT Guwahati ‚Üí established second pillar, especially strong in ergonomics. New but Promising: IIT Delhi ‚Üí compact, high industry connect (Delhi-NCR). IIT Hyderabad ‚Üí experimental, digital-first, AR/VR heavy. IIT Indore ‚Üí thematic, sustainability-driven (ideal for research/global masters). Engineering‚ÄìDesign Hybrids: IIT Roorkee ‚Üí ergonomics + manufacturing focus. IIITDM Jabalpur ‚Üí design + IT + manufacturing, but recruiter skew toward IT. Stream Restrictions: Arts/Commerce students ‚Üí Only eligible for IIT Bombay, IIT Delhi, IIT Hyderabad, IIT Indore. Science PCM students ‚Üí Eligible for all, but ergonomics-heavy IITG/IITR/IIITDM may suit them better. Placement Quality: Strongest recruiter visibility: IIT Bombay, IIT Guwahati, IIT Hyderabad. IIT Roorkee + IIITDM ‚Üí more engineering/auto/IT-heavy recruiter mix. IIT Delhi \u0026 IIT Indore ‚Üí too new; rely on self-driven portfolios and startup ecosystem. ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:4:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"‚úÖ Recommendation Framework For broadest opportunities (creative + product + animation): IIT Bombay. For ergonomics, usability, engineering-linked design: IIT Guwahati or IIT Roorkee. For experimental AR/VR, UX, emerging media: IIT Hyderabad. For Delhi-NCR industry/startups, product + branding: IIT Delhi. For IT + manufacturing design careers: IIITDM Jabalpur. For sustainability, healthcare, system-level design + research: IIT Indore. ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:5:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"References ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:6:0","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"üîπ Official IIT Design School Sources IIT Bombay (IDC): https://www.idc.iitb.ac.in/academic/bdes-program IIT Delhi (DoD): https://design.iitd.ac.in/programs-b-des.html ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:6:1","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"üîπ Admission / Course Details (General \u0026 Multiple IITs) Careers360 ‚Äì IIT B.Des admission, courses, fees: https://design.careers360.com/articles/iit-bdes-admission-courses-and-fees Silica Institute ‚Äì How to apply for IIT B.Des via UCEED (seat matrix, counselling): https://silica.co.in/blog/how-to-apply-for-b-des-programs-at-iits Opasis ‚Äì IIT B.Des eligibility (stream-specific rules for Arts/Commerce/Science): https://www.opasis.com/public/school/blogdetails/IITs%2BOpening%2BDoors%2Bfor%2BNon-Science%2BStudents%3A%2BApply%2Bfor%2BB.Design%2Bvia%2BUCEED ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:6:2","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"üîπ Entrance Exam Information UCEED (Wikipedia): https://en.wikipedia.org/wiki/UCEED ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:6:3","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"üîπ IIT Indore B.Des Program News Times of India ‚Äì IIT Indore launches first batch of B.Des: https://timesofindia.indiatimes.com/city/indore/iit-i-launches-first-batch-of-bdes/articleshow/123149969.cms ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:6:4","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Education","Courses"],"content":"üîπ Additional Context / Alumni Insights iQuanta Blog ‚Äì Design programs at IITs: https://www.iquanta.in/blog/design-programs-offered-at-iits Reddit (student experiences, placements, recruiters for IITB/Guwhati B.Des): https://www.reddit.com/r/Indian_Academia/comments/pujx59/how_is_the_bdes_course_from_iit_bombay_guvahati Technically authored by me, with insights assisted by ChatGPT. Happy Learning! ","date":"2025-08-28","objectID":"/posts/iit_bdes_program_information/:6:5","tags":["IIT","BDes","Design","Academic Research","Graduation"],"title":"IIT BDes Programs awareness material","uri":"/posts/iit_bdes_program_information/"},{"categories":["Personal","Technology"],"content":"Disclaimer: The original song, its music, and lyrics belong entirely to their respective creators and copyright holders. This post is purely a personal reflection as a fan, exploring how technology enables new forms of creative enjoyment. All rights and ownership of the original work remain with the rightful creators. ‚ÄòStill any concerns or worries about the content, thought or anything, please reach out through DM LinkedIn‚Äô Okie now let us enjoy the moment. There are certain songs that stay with you‚Äînot just as music, but as emotions you can revisit anytime. Recently, I spent some quiet time with one of my favourite Tamil songs: Watch on YouTube. This song has always fascinated me with its beautiful lyrics and mesmerising music. As a fan of art and technology, I wanted to explore how far today‚Äôs tools can help me experience a song in new dimensions‚Äîwithout ever taking away from the originality or essence of the work. Original Lyrics \"**‡Æï‡Æ©‡Æµ‡Øá ‡Æï‡Æ©‡Æµ‡Øá**\" ‡ÆÆ‡Øå‡Æ©‡ÆÆ‡Ææ‡Æ© ‡ÆÆ‡Æ∞‡Æ£‡ÆÆ‡Øç ‡Æí‡Æ©‡Øç‡Æ±‡ØÅ ‡Æâ‡ÆØ‡Æø‡Æ∞‡Øà ‡Æï‡Øä‡Æ£‡Øç‡Æü‡ØÅ ‡Æ™‡Øã‡Æ©‡Æ§‡Øá ‡Æâ‡ÆØ‡Æ∞‡ÆÆ‡Ææ‡Æ© ‡Æï‡Æ©‡Æµ‡ØÅ ‡Æá‡Æ©‡Øç‡Æ±‡ØÅ ‡Æ§‡Æ∞‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡Æµ‡ØÄ‡Æ¥‡Øç‡Æ®‡Øç‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ©‡Æ§‡Øá ‡Æ§‡Æø‡Æö‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ©‡Æ§‡ØÅ ‡Æ§‡Æø‡ÆÆ‡Æø‡Æ∞‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ©‡Æ§‡ØÅ ‡Æ§‡Æ©‡Æø‡ÆÆ‡Øà ‡Æ§‡ØÄ‡ÆØ‡Æø‡Æ≤‡Øá ‡Æµ‡Ææ‡Æü‡Æø‡Æ©‡Øá‡Æ©‡Øç ‡Æ®‡Æø‡Æ¥‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ©‡Æ§‡ØÅ ‡Æ®‡Æø‡Æú‡ÆÆ‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ©‡Æ§‡ØÅ ‡Æé‡Æ©‡Æï‡Øç‡Æï‡ØÅ‡Æ≥‡Øç ‡Æé‡Æ©‡Øà‡ÆØ‡Øá ‡Æ§‡Øá‡Æü‡Æø‡Æ©‡Øá‡Æ©‡Øç ‡Æï‡Æ©‡Æµ‡Øá ‡Æï‡Æ©‡Æµ‡Øá ‡Æï‡Æ≤‡Øà‡Æµ‡Æ§‡Øá‡Æ©‡Øã ‡Æï‡Æ∞‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ∞‡Æ£‡ÆÆ‡Ææ‡ÆØ‡Øç ‡Æï‡Æ∞‡Øà‡Æµ‡Æ§‡Øá‡Æ©‡Øã ‡Æ®‡Æø‡Æ©‡Øà‡Æµ‡Øá ‡Æ®‡Æø‡Æ©‡Øà‡Æµ‡Øá ‡ÆÖ‡Æ∞‡Øà‡Æµ‡Æ§‡Øá‡Æ©‡Øã ‡Æé‡Æ©‡Æ§‡ØÅ ‡Æâ‡Æ≤‡Æï‡ÆÆ‡Øç ‡Æâ‡Æü‡Øà‡Æµ‡Æ§‡Øá‡Æ©‡Øã ‡Æï‡Æ£‡Øç‡Æï‡Æ≥‡Øç ‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æ®‡ØÄ‡Æ∞‡Æø‡Æ≤‡Øá ‡ÆÆ‡ØÄ‡Æ©‡Øà ‡Æ™‡Øã‡Æ≤ ‡Æµ‡Ææ‡Æ¥‡ØÅ‡Æ§‡Øá ‡Æï‡Æü‡Æµ‡ØÅ‡Æ≥‡ØÅ‡ÆÆ‡Øç ‡Æ™‡ØÜ‡Æ£‡Øç ‡Æá‡Æ§‡ÆØ‡ÆÆ‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ§‡Ææ ‡ÆÖ‡Æü ‡Æá‡Æ≤‡Øç‡Æ≤‡Øà‡ÆØ‡Ææ ‡Æì‡Æπ‡Øã ‡Æ®‡Ææ‡Æ©‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æô‡Øç‡Æï‡Øá ‡Æµ‡Æ≤‡Æø‡ÆØ‡Æø‡Æ≤‡Øá ‡Æ®‡ØÄ‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æô‡Øç‡Æï‡Øã ‡Æö‡Æø‡Æ∞‡Æø‡Æ™‡Øç‡Æ™‡Æø‡Æ≤‡Øá ‡Æï‡Ææ‡Æ±‡Øç‡Æ±‡Æø‡Æ≤‡Øç ‡Æé‡Æô‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æ§‡Øá‡Æü‡Æø‡Æ©‡Øá‡Æ©‡Øç ‡Æ™‡Øá‡Æö‡Æø ‡Æ™‡Øã‡Æ© ‡Æµ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡Øà‡ÆØ‡Øà ‡Æá‡Æ§‡ØÅ ‡Æ®‡Æø‡ÆØ‡Ææ‡ÆØ‡ÆÆ‡Ææ ‡ÆÆ‡Æ©‡ÆÆ‡Øç ‡Æ§‡Ææ‡Æô‡Øç‡Æï‡ØÅ‡ÆÆ‡Ææ ‡Æé‡Æ©‡Øç ‡ÆÜ‡Æö‡Øà‡Æï‡Æ≥‡Øç ‡ÆÖ‡Æ§‡ØÅ ‡Æ™‡Ææ‡Æµ‡ÆÆ‡Ææ... ‡Æï‡Æ©‡Æµ‡Øá ‡Æï‡Æ©‡Æµ‡Øá... ‡Æï‡Æ∞‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ∞‡Æ£‡ÆÆ‡Ææ‡ÆØ‡Øç... ‡Æ®‡Æø‡Æ©‡Øà‡Æµ‡Øá ‡Æ®‡Æø‡Æ©‡Øà‡Æµ‡Øá ‡ÆÖ‡Æ∞‡Øà‡Æµ‡Æ§‡Øá‡Æ©‡Øã ‡Æé‡Æ©‡Æ§‡ØÅ ‡Æâ‡Æ≤‡Æï‡ÆÆ‡Øç ‡Æâ‡Æü‡Øà‡Æµ‡Æ§‡Øá‡Æ©‡Øã To test the artistic ability of AI I began by taking the original Tamil lyrics and, with the help of ChatGPT, created an English version that retained the emotional essence of the song. It wasn‚Äôt a literal translation‚Äîit was more like a heartfelt interpretation. After a few rounds of revisions, I had a version that I felt captured the mood I experience whenever I listen to the song. This process itself was enjoyable. It was a dialogue between my heart, the song‚Äôs essence, and a tool that could reflect and refine my thoughts. It is always fun to talk to a reflection of you with more abilities to express easily what you felt. Here is the output **\"Dream oh my dream\"** A silent death stole a soul away, A lofty dream fell to the earth today. Pride departed, directions blurred, In the flames of solitude, I burned. Shadows faded, truths dissolved, Within myself, I searched, unresolved. Oh dream, oh dream, why do you fade? Why do these hands bear scars that won‚Äôt abate? Oh memory, oh memory, why do you wane? Why does my world shatter in pain? Eyes adrift in streams of tears, Living like a fish in waters unclear. Does God exist, does love endure? Or is it all a lie, a fate unsure? Here I am, engulfed in pain, There you are, smiling again. I searched the winds for words once spoken, Only to find promises broken. Is this just? Can my heart sustain? Are my dreams a sin, a source of blame? Once you get the output as a developer you always wanted to share and see the output. A moment of visualising the output always a sense of satisfaction. I also wanted to visualise the output in an art form. Started imagining how the scene would be I turned them into prompts to generate images using ChatGPT and the Flux model for image generation. Watching the tool produce visual interpretations of the emotion I felt was a moment of pure euphoria. Prompt used to generate image in both the AI tools: A somber, emotional scene set in a quiet, desolate landscape at dusk. A lone figure, dressed in dark, tattered clothing, sits on the ground, head bowed, surrounded by broken, feathered wings scattered like remnants of shattered dreams. The background is vast and barren, with a faint, blurred horizon symbolizing lost direction. Fading silhouettes of memories, like translucent shadows, drift into the air. Nearby, a small pool of water reflects the figure's tear-streaked face, with their eyes resembling a fish swimming in sorrow. In the distance, a faintly vi","date":"2025-08-03","objectID":"/posts/technology_meets_art_a_fan_moment/:0:0","tags":["AI","Art","Music","Personal Reflection","suno.ai","FLUX Model","ChatGPT","Fun"],"title":"Technology meets Art: A fan moment","uri":"/posts/technology_meets_art_a_fan_moment/"},{"categories":["Technology","AI Tools"],"content":"How I use ChatGPT as a professional companion for design, debugging, documentation, and accelerating technical learning without replacing human creativity.","date":"2025-08-02","objectID":"/posts/leveraging_chatgpt_as_a_professional_companion/","tags":["ChatGPT","OpenAI","AI Productivity","LLM","ChatGPT4o"],"title":"Leveraging ChatGPT as a Professional Companion","uri":"/posts/leveraging_chatgpt_as_a_professional_companion/"},{"categories":["Technology","AI Tools"],"content":"Leveraging ChatGPT as a Professional Companion In my professional journey, I increasingly rely on AI-assisted workflows to accelerate research, enhance documentation, debug complex scenarios, and organize my thoughts effectively. Among these tools, ChatGPT (OpenAI‚Äôs ChatGPT4o) has become a professional companion‚Äî not a replacement for creativity, but a force multiplier in productivity and structured thinking. ","date":"2025-08-02","objectID":"/posts/leveraging_chatgpt_as_a_professional_companion/:0:0","tags":["ChatGPT","OpenAI","AI Productivity","LLM","ChatGPT4o"],"title":"Leveraging ChatGPT as a Professional Companion","uri":"/posts/leveraging_chatgpt_as_a_professional_companion/"},{"categories":["Technology","AI Tools"],"content":"1Ô∏è‚É£ How ChatGPT Enhances My Workflow I use ChatGPT for: Debugging \u0026 Troubleshooting complex issues faster Structuring learning notes in a clear, professional format Assisting in architecture \u0026 design reflections for enterprise projects Drafting professional posts and documentation efficiently It integrates seamlessly into my workflow with Hugo + LoveIt blogs, Markdown-based documentation, and LLM-driven experiments. I see ChatGPT as an AI pair-programmer for thought and structure, helping me stay productive while maintaining my own decision-making and engineering judgment. ","date":"2025-08-02","objectID":"/posts/leveraging_chatgpt_as_a_professional_companion/:1:0","tags":["ChatGPT","OpenAI","AI Productivity","LLM","ChatGPT4o"],"title":"Leveraging ChatGPT as a Professional Companion","uri":"/posts/leveraging_chatgpt_as_a_professional_companion/"},{"categories":["Technology","AI Tools"],"content":"2Ô∏è‚É£ Professional Gratitude and Responsible Usage This post is a note of appreciation for ChatGPT and similar AI tools. While they assist with research and content organization, human creativity and reasoning remain central. I consciously: Validate AI outputs against my expertise before use Avoid blind copy-paste in critical work Ensure transparency in assisted content creation ","date":"2025-08-02","objectID":"/posts/leveraging_chatgpt_as_a_professional_companion/:2:0","tags":["ChatGPT","OpenAI","AI Productivity","LLM","ChatGPT4o"],"title":"Leveraging ChatGPT as a Professional Companion","uri":"/posts/leveraging_chatgpt_as_a_professional_companion/"},{"categories":["Technology","AI Tools"],"content":"3Ô∏è‚É£ Perceptions and Transparency in AI Usage People have different views on AI-assisted work: Some embrace it as a skill, Others perceive it as over-reliance. I believe responsible AI adoption is a professional advantage‚Äî what matters is how you direct, validate, and use the tool to amplify human capability. ‚ÄúTools don‚Äôt replace expertise; they enhance the ability to execute ideas efficiently.‚Äù ","date":"2025-08-02","objectID":"/posts/leveraging_chatgpt_as_a_professional_companion/:3:0","tags":["ChatGPT","OpenAI","AI Productivity","LLM","ChatGPT4o"],"title":"Leveraging ChatGPT as a Professional Companion","uri":"/posts/leveraging_chatgpt_as_a_professional_companion/"},{"categories":["Technology","AI Tools"],"content":"4Ô∏è‚É£ Closing Note Using ChatGPT as a professional companion has: Expanded my learning capacity Improved documentation quality Enabled structured knowledge sharing through my website I remain grateful for the synergy between human insight and AI assistance. Technically authored by me, with insights assisted by ChatGPT. Happy Learning! ","date":"2025-08-02","objectID":"/posts/leveraging_chatgpt_as_a_professional_companion/:4:0","tags":["ChatGPT","OpenAI","AI Productivity","LLM","ChatGPT4o"],"title":"Leveraging ChatGPT as a Professional Companion","uri":"/posts/leveraging_chatgpt_as_a_professional_companion/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Learn how to build a reactive file processing pipeline in Java using Spring Boot, Quarkus, MQTT, and PostgreSQL. Compare Project Reactor vs Mutiny with a microservices architecture.","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part1/","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 1","uri":"/posts/reactive_springboot_vs_quarkus_part1/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":" Loading markdown... ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part1/:0:0","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 1","uri":"/posts/reactive_springboot_vs_quarkus_part1/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Reactive Series: post links üîó Part2: üîó Part3: üîó Part4: üîó Part5: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part1/:0:1","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 1","uri":"/posts/reactive_springboot_vs_quarkus_part1/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Learn how to build a reactive file processing pipeline in Java using Spring Boot, Quarkus, MQTT, and PostgreSQL. Compare Project Reactor vs Mutiny with a microservices architecture.","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part2/","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 2","uri":"/posts/reactive_springboot_vs_quarkus_part2/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":" Loading markdown... ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part2/:0:0","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 2","uri":"/posts/reactive_springboot_vs_quarkus_part2/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Reactive Series: post links üîó Part1: üîó Part3: üîó Part4: üîó Part5: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part2/:0:1","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 2","uri":"/posts/reactive_springboot_vs_quarkus_part2/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Learn how to build a reactive file processing pipeline in Java using Spring Boot, Quarkus, MQTT, and PostgreSQL. Compare Project Reactor vs Mutiny with a microservices architecture.","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part3/","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 3","uri":"/posts/reactive_springboot_vs_quarkus_part3/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":" Loading markdown... ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part3/:0:0","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 3","uri":"/posts/reactive_springboot_vs_quarkus_part3/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Reactive Series: post links üîó Part1: üîó Part2: üîó Part4: üîó Part5: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part3/:0:1","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 3","uri":"/posts/reactive_springboot_vs_quarkus_part3/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Learn how to build a reactive file processing pipeline in Java using Spring Boot, Quarkus, MQTT, and PostgreSQL. Compare Project Reactor vs Mutiny with a microservices architecture.","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part4/","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 4","uri":"/posts/reactive_springboot_vs_quarkus_part4/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":" Loading markdown... ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part4/:0:0","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 4","uri":"/posts/reactive_springboot_vs_quarkus_part4/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Reactive Series: post links üîó Part1: üîó Part2: üîó Part3: üîó Part5: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part4/:0:1","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 4","uri":"/posts/reactive_springboot_vs_quarkus_part4/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Learn how to build a reactive file processing pipeline in Java using Spring Boot, Quarkus, MQTT, and PostgreSQL. Compare Project Reactor vs Mutiny with a microservices architecture.","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part5/","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 5","uri":"/posts/reactive_springboot_vs_quarkus_part5/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":" Loading markdown... ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part5/:0:0","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 5","uri":"/posts/reactive_springboot_vs_quarkus_part5/"},{"categories":["Java","ReactiveProgramming","Technology"],"content":"Reactive Series: post links üîó Part1: üîó Part2: üîó Part3: üîó Part4: ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-02","objectID":"/posts/reactive_springboot_vs_quarkus_part5/:0:1","tags":["Spring Boot","Quarkus","Reactive Streams","MQTT","Microservices","Project Reactor","Mutiny"],"title":"Reactive File Processing with MQTT: Spring Boot vs Quarkus ‚Äì Part 5","uri":"/posts/reactive_springboot_vs_quarkus_part5/"},{"categories":["Whitepaper","Recruitment"],"content":"A whitepaper introducing the Cognitive-Presence Index (CPI), a human-first AI-assisted talent discovery framework combining ethical governance, reflective evaluation, and cognitive profiling.","date":"2025-08-02","objectID":"/posts/towards_an_ethical_cognitive_presence_index/","tags":["AI Ethics","Talent Discovery","Recruitment Innovation","Human-Centric AI","Cognitive Presence"],"title":"Towards an Ethical Cognitive-Presence Index (CPI)","uri":"/posts/towards_an_ethical_cognitive_presence_index/"},{"categories":["Whitepaper","Recruitment"],"content":" Loading markdown... ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-02","objectID":"/posts/towards_an_ethical_cognitive_presence_index/:0:0","tags":["AI Ethics","Talent Discovery","Recruitment Innovation","Human-Centric AI","Cognitive Presence"],"title":"Towards an Ethical Cognitive-Presence Index (CPI)","uri":"/posts/towards_an_ethical_cognitive_presence_index/"},{"categories":["WebDevelopment","HugoTips"],"content":"Learn how to dynamically render Markdown in Hugo with Mermaid diagrams, MathJax, GitHub-style tables, and a dynamic Table of Contents (TOC).","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"Enhancing Hugo with Dynamic Markdown, Mermaid, and Styled TOC After building my Hugo + LoveIt personal website, I wanted to explore how to render Markdown dynamically in the browser instead of pre‚Äërendering all content at Hugo build time. In this guide, you will learn how to: Render raw Markdown files dynamically with a GitHub‚Äëstyle viewer Add Mermaid diagrams for flowcharts and sequence diagrams Enable MathJax for inline math expressions Apply GitHub‚Äëstyle tables and code block styling Generate a dynamic Table of Contents (TOC) at runtime ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:0","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"1 Why Dynamic Markdown Rendering By default, Hugo converts Markdown in content/ into static HTML at build time. This is great for most blogs, but it has limitations if you want: To view standalone .md files directly (perfect for sharing raw notes) To avoid converting Markdown into Hugo shortcodes every time To experiment with a GitHub‚Äëstyle Markdown viewer on your site To achieve this, I used Marked.js to render Markdown at runtime directly in the browser. ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:1","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"2 Adding Dynamic Markdown Viewer To enable runtime Markdown rendering in Hugo, I created: A custom layout ‚Üí layouts/markdown-viewer.html A JavaScript renderer ‚Üí static/js/markdown-viewer.js The script: Fetches Markdown files from static/files/*.md Renders them with Marked.js Applies syntax highlighting with Highlight.js HTML Structure: \u003cdiv id=\"markdown-container\" data-file=\"/files/sample.md\"\u003e Loading markdown... \u003c/div\u003e \u003c!-- Include scripts --\u003e \u003clink rel=\"stylesheet\" href=\"/css/github-markdown.min.css\"\u003e \u003cscript src=\"/js/marked.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/highlight.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/markdown-viewer.js\"\u003e\u003c/script\u003e ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:2","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"3 Table Styling and GitHub Look By default, Markdown tables in Hugo are plain and lack visual distinction. To improve readability, I added GitHub‚Äëstyle table formatting: border-collapse: collapse; margin: 1rem 0; width: 100%; } .markdown-body th, .markdown-body td { border: 1px solid #d0d7de; padding: 6px 13px; } .markdown-body tr:nth-child(even) { background-color: #f6f8fa; } And ensured markdown-viewer.js adds .markdown-body class for styling. All tables automatically inherit GitHub-like styling. ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:3","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"4 Adding Mermaid Diagram Support LoveIt does not natively support Mermaid for dynamically loaded Markdown. Steps I followed: Added Mermaid.js to static/js/mermaid.min.js In markdown-viewer.js, converted fenced code blocks: // Convert mermaid code fences into container.querySelectorAll('pre code.language-mermaid').forEach(block =\u003e { const div = document.createElement('div'); div.classList.add('mermaid'); div.textContent = block.textContent; block.parentNode.replaceWith(div); }); if (window.mermaid) { mermaid.initialize({ startOnLoad: false }); mermaid.run({ querySelector: \".mermaid\" }); } Now my Markdown with: ```mermaid graph TD A[Start] --\u003e B[Process] --\u003e C[End] ``` ‚Ä¶renders a live Mermaid diagram in the browser. ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:4","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"5 MathJax for Math Expressions To support LaTeX‚Äëstyle math like: $$ 10 \\mod 7 = 3 $$ I included MathJax v3: \u003cscript\u003e window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\\\(', '\\\\)']] }, svg: { fontCache: 'global' } }; \u003c/script\u003e \u003cscript src=\"/js/tex-svg.js\"\u003e\u003c/script\u003e Then triggered it in JS: if (window.MathJax) { window.MathJax.typesetPromise(); } ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:5","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"6 Dynamic Table of Contents (TOC) Hugo normally builds TOC at build time. Since my Markdown is dynamic, I built the TOC after rendering: Detected headings h1, h2, h3 in #markdown-container Populated the existing LoveIt \u003cnav id=\"TableOfContents\"\u003e dynamically Simplified Example: const tocNav = document.getElementById(\"TableOfContents\"); const headings = container.querySelectorAll(\"h1, h2, h3\"); if (tocNav \u0026\u0026 headings.length \u003e 0) { const ul = document.createElement(\"ul\"); headings.forEach(h =\u003e { const id = h.id || h.textContent.trim().replace(/\\s+/g, \"-\").toLowerCase(); h.id = id; const li = document.createElement(\"li\"); const a = document.createElement(\"a\"); a.textContent = h.textContent; a.href = \"#\" + id; li.appendChild(a); ul.appendChild(li); }); tocNav.innerHTML = \"\"; tocNav.appendChild(ul); } Now LoveIt‚Äôs floating TOC shows headings for dynamically loaded Markdown too. ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:6","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"7 I‚Äôll show step‚Äëby‚Äëstep how to Create a HTML viewer layout in Hugo Add a JavaScript file to render Markdown dynamically Support Mermaid diagrams, MathJax formulas, and GitHub‚Äëstyle tables Generate a dynamic Table of Contents (TOC) for the loaded Markdown file 7.1 Create a Hugo Layout for the Markdown Viewer Inside your Hugo project: layouts/markdown-viewer.html Example: html {{- define \"title\" }}{{ .Title }} - {{ .Site.Title }}{{ end -}} {{- define \"content\" -}} \u003c!-- Markdown Viewer Scripts --\u003e \u003c!-- MathJax v3 Configuration --\u003e \u003cscript\u003e window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\\\(', '\\\\)']] }, svg: { fontCache: 'global' } }; \u003c/script\u003e \u003c!-- Load MathJax AFTER config --\u003e \u003cscript src=\"/js/tex-svg.js\"\u003e\u003c/script\u003e \u003c!-- \u003clink rel=\"stylesheet\" href=\"/css/markdown-viewer.css\"\u003e --\u003e \u003clink rel=\"stylesheet\" href=\"/css/github.min.css\"\u003e \u003clink rel=\"stylesheet\" href=\"/css/github-markdown.min.css\"\u003e \u003cscript src=\"/js/marked.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/highlight.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/markdown-viewer.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/mermaid.min.js\"\u003e\u003c/script\u003e \u003cscript\u003e mermaid.initialize({ startOnLoad: false }); \u003c/script\u003e \u003c!-- Markdown Viewer Scripts --\u003e {{- $params := .Scratch.Get \"params\" -}} {{- $toc := $params.toc -}} {{- if eq $toc true -}} {{- $toc = .Site.Params.page.toc | default dict -}} {{- else if eq $toc false -}} {{- $toc = dict \"enable\" false -}} {{- end -}} {{- /* Auto TOC */ -}} {{- if ne $toc.enable false -}} \u003cdiv class=\"toc\" id=\"toc-auto\"\u003e \u003ch2 class=\"toc-title\"\u003e{{ T \"contents\" }}\u003c/h2\u003e \u003cdiv class=\"toc-content{{ if eq $toc.auto false }} always-active{{ end }}\" id=\"toc-content-auto\"\u003e\u003c/div\u003e \u003c/div\u003e {{- end -}} \u003carticle class=\"page single\"\u003e {{- /* Title */ -}} \u003ch1 class=\"single-title animate__animated animate__flipInX\"\u003e{{ .Title | emojify }}\u003c/h1\u003e {{- /* Subtitle */ -}} {{- with $params.subtitle -}} \u003ch2 class=\"single-subtitle\"\u003e{{ . }}\u003c/h2\u003e {{- end -}} {{- /* Meta */ -}} \u003cdiv class=\"post-meta\"\u003e \u003cdiv class=\"post-meta-line\"\u003e {{- $author := $params.author | default .Site.Params.Author.name | default (T \"author\") -}} {{- $authorLink := $params.authorlink | default .Site.Params.Author.link | default .Site.Home.RelPermalink -}} \u003cspan class=\"post-author\"\u003e {{- $options := dict \"Class\" \"author\" \"Destination\" $authorLink \"Title\" \"Author\" \"Rel\" \"author\" \"Icon\" (dict \"Class\" \"fas fa-user-circle fa-fw\") \"Content\" $author -}} {{- partial \"plugin/a.html\" $options -}} \u003c/span\u003e {{- $categories := slice -}} {{- range .Params.categories -}} {{- $category := partialCached \"function/path.html\" . . | printf \"/categories/%v\" | $.Site.GetPage -}} {{- $categories = $categories | append (printf `\u003ca href=\"%v\"\u003e\u003ci class=\"far fa-folder fa-fw\" aria-hidden=\"true\"\u003e\u003c/i\u003e%v\u003c/a\u003e` $category.RelPermalink $category.Title) -}} {{- end -}} {{- with delimit $categories \"\u0026nbsp;\" -}} \u0026nbsp;\u003cspan class=\"post-category\"\u003e {{- dict \"Categories\" . | T \"includedInCategories\" | safeHTML -}} \u003c/span\u003e {{- end -}} \u003c/div\u003e \u003cdiv class=\"post-meta-line\"\u003e {{- with .Site.Params.dateformat | default \"2006-01-02\" | .PublishDate.Format -}} \u003ci class=\"far fa-calendar-alt fa-fw\" aria-hidden=\"true\"\u003e\u003c/i\u003e\u0026nbsp;\u003ctime datetime=\"{{ . }}\"\u003e{{ . }}\u003c/time\u003e\u0026nbsp; {{- end -}} \u003ci class=\"fas fa-pencil-alt fa-fw\" aria-hidden=\"true\"\u003e\u003c/i\u003e\u0026nbsp;{{ T \"wordCount\" .WordCount }}\u0026nbsp; \u003ci class=\"far fa-clock fa-fw\" aria-hidden=\"true\"\u003e\u003c/i\u003e\u0026nbsp;{{ T \"readingTime\" .ReadingTime }}\u0026nbsp; {{- $comment := .Scratch.Get \"comment\" | default dict -}} {{- if $comment.enable | and $comment.valine.enable | and $comment.valine.visitor -}} \u003cspan id=\"{{ .RelPermalink }}\" class=\"leancloud_visitors\" data-flag-title=\"{{ .Title }}\"\u003e \u003ci class=\"far fa-eye fa-fw\" aria-hidden=\"true\"\u003e\u003c/i\u003e\u0026nbsp;\u003cspan class=leancloud-visitors-count\u003e\u003c/span\u003e\u0026nbsp;{{ T \"views\" }} \u003c/span\u003e\u0026nbsp; {{- end -}} \u003c/div\u003e \u003c/div\u003e {{- /* Featured image */ -}} {{- $image := $params.featuredimage -}} {{- with .Resources.GetMatch \"featured-image\" -}} {{- $image = .RelPermalink -}} {{- end -}} {{- with $image -}} \u003cdiv class=\"featured-image\"\u003e {{- dict \"Src\" . \"Title","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:7","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["WebDevelopment","HugoTips"],"content":"8 Test in Local Hugo Server hugo server -D Open the page: http://localhost:1313/posts/markdown-demo/ You should see: Rendered Markdown Highlighted code Mermaid diagram Math formula GitHub‚Äëstyle table Floating TOC ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-08-01","objectID":"/posts/enhancing_hugo_with_dynamic_markdown/:1:8","tags":["Hugo","LoveIt","Markdown Viewer","Mermaid","MathJax","Dynamic TOC"],"title":"Enhancing Hugo with Dynamic Markdown, Mermaid, and TOC","uri":"/posts/enhancing_hugo_with_dynamic_markdown/"},{"categories":["Mathematics","Cryptography"],"content":"Learn the mathematical foundation of Shamir's Secret Sharing (SSS), including modular arithmetic, finite fields, and polynomial interpolation for cryptographic security.","date":"2025-07-31","objectID":"/posts/mathematical_foundation_and_sss/","tags":["Shamir's Secret Sharing","SSS","Finite Field","Polynomial Interpolation","Cryptography Algorithms"],"title":"Mathematical Foundation of Shamir's Secret Sharing (SSS)","uri":"/posts/mathematical_foundation_and_sss/"},{"categories":["Mathematics","Cryptography"],"content":" Loading markdown... ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-07-31","objectID":"/posts/mathematical_foundation_and_sss/:0:0","tags":["Shamir's Secret Sharing","SSS","Finite Field","Polynomial Interpolation","Cryptography Algorithms"],"title":"Mathematical Foundation of Shamir's Secret Sharing (SSS)","uri":"/posts/mathematical_foundation_and_sss/"},{"categories":["Mathematics","Cryptography"],"content":"Learn polynomial concepts and Lagrange interpolation to understand Shamir's Secret Sharing (SSS) and how k-of-n secret reconstruction works using finite field arithmetic.","date":"2025-07-31","objectID":"/posts/polynomial_and_lagrange_interpolation/","tags":["Shamir's Secret Sharing","SSS","Lagrange Interpolation","Polynomial","Finite Field"],"title":"Polynomial and Lagrange Interpolation for Shamir's Secret Sharing (SSS)","uri":"/posts/polynomial_and_lagrange_interpolation/"},{"categories":["Mathematics","Cryptography"],"content":" Loading markdown... ‚ÄúTechnically authored by me, accelerated with insights from ChatGPT by OpenAI.‚Äù Refer: Leverage ChatGPT Happy Learning ","date":"2025-07-31","objectID":"/posts/polynomial_and_lagrange_interpolation/:0:0","tags":["Shamir's Secret Sharing","SSS","Lagrange Interpolation","Polynomial","Finite Field"],"title":"Polynomial and Lagrange Interpolation for Shamir's Secret Sharing (SSS)","uri":"/posts/polynomial_and_lagrange_interpolation/"},{"categories":["Personal","Technology"],"content":"Senior Delivery Architect and AI Enthusiast. Passionate about building secure, scalable cloud and AI-driven solutions integrating LLM, data, and event-driven systems.","date":"2025-07-31","objectID":"/about/","tags":["About","AI Enthusiast","Cloud Architect","Event-Driven Systems"],"title":"About Me | Kathiravan Muthaiah","uri":"/about/"},{"categories":["Personal","Technology"],"content":" Kathiravan Muthaiah Senior Delivery Architect | Technologist \u0026 AI Enthusiast ","date":"2025-07-31","objectID":"/about/:0:0","tags":["About","AI Enthusiast","Cloud Architect","Event-Driven Systems"],"title":"About Me | Kathiravan Muthaiah","uri":"/about/"},{"categories":["Personal","Technology"],"content":"üëã Hello! I am a technology architect and lifelong learner passionate about designing scalable, secure, and intelligent systems that blend cloud, data, and AI. I enjoy turning complex ideas into practical solutions, balancing architecture with hands-on coding and experimentation. ","date":"2025-07-31","objectID":"/about/:0:1","tags":["About","AI Enthusiast","Cloud Architect","Event-Driven Systems"],"title":"About Me | Kathiravan Muthaiah","uri":"/about/"},{"categories":["Personal","Technology"],"content":"‚ö° Technical Curiosities Event-driven \u0026 Distributed Systems Cloud-native \u0026 Containerized Workloads Data Intelligence \u0026 AI Integration (LLM, Graph, Vector) Security, Observability \u0026 Reliable System Design I enjoy exploring how emerging technologies can simplify real-world problems. Experimenting with new programming frameworks \u0026 event pipelines Building Perceptional view to reveal insights from data Tracking some metrics \u0026 productivity patterns for self-understanding and if possible improve. ","date":"2025-07-31","objectID":"/about/:0:2","tags":["About","AI Enthusiast","Cloud Architect","Event-Driven Systems"],"title":"About Me | Kathiravan Muthaiah","uri":"/about/"},{"categories":["Personal","Technology"],"content":"üå± Beyond Work Outside of tech, I enjoy quiet explorations, reflection, and simplifying complex things I believe in learning by doing. ","date":"2025-07-31","objectID":"/about/:0:3","tags":["About","AI Enthusiast","Cloud Architect","Event-Driven Systems"],"title":"About Me | Kathiravan Muthaiah","uri":"/about/"},{"categories":["Personal","Technology"],"content":"üîó Let‚Äôs connect GitHub LinkedIn ‚úâÔ∏è DM in Linkedin Explore my recent posts ","date":"2025-07-31","objectID":"/about/:0:4","tags":["About","AI Enthusiast","Cloud Architect","Event-Driven Systems"],"title":"About Me | Kathiravan Muthaiah","uri":"/about/"}]